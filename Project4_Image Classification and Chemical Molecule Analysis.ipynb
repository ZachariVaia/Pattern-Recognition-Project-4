{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "5vzyS3IaEDf3",
        "v1xx4HIHBR_1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Τελική Εργασία\n",
        "\n",
        "# Αναγνώριση Προτύπων\n",
        "\n",
        "Ζαχάρη Βάια 58161"
      ],
      "metadata": {
        "id": "zfuNsz9QBD29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ΜΕΡΟΣ Α**"
      ],
      "metadata": {
        "id": "5vzyS3IaEDf3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjUC7qCr-Uib",
        "outputId": "c3ebaddc-874a-4acc-fc65-7b73d05d579e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p \"/content/final\"\n",
        "!unzip -q \"/content/drive/My Drive/final_project_protupa/Mask_DB.zip\" -d \"/content/final\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Α)**Χωρίζουμε τα δεδομένα τυχαία σε 60% δεδομένα εκπαίδευσης, 20% δεδομένα επικύρωσης και 20% δεδομένα δοκιμής."
      ],
      "metadata": {
        "id": "Q6rPg7tfEO2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets\n",
        "from skimage import transform\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader ,TensorDataset, random_split\n",
        "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# hyper-parameters\n",
        "num_epochs = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "gLJ4yJmyHCHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Συνάρτηση για τη φόρτωση εικόνων και την μετατροπή τους σε numpy arrays\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = Image.open(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            images.append(np.array(img))\n",
        "            labels.append(1 if \"with_mask\" in folder else 0)\n",
        "    return images, labels\n",
        "\n",
        "# Φόρτωση εικόνων από τους φακέλους\n",
        "with_mask_images, with_mask_labels = load_images_from_folder('/content/final/with_mask')\n",
        "without_mask_images, without_mask_labels = load_images_from_folder('/content/final/without_mask')\n",
        "\n",
        "# Συνένωση των λιστών εικόνων και των ετικετών\n",
        "all_images = np.array(with_mask_images + without_mask_images)\n",
        "all_labels = np.array(with_mask_labels + without_mask_labels)\n",
        "\n",
        "# Δημιουργία PyTorch tensors για τις εικόνες και τις ετικέτες\n",
        "all_labels_tensor = torch.tensor(all_labels).long()   # Μετατροπή των ετικετών σε PyTorch tensors\n",
        "# Υποθέτοντας ότι all_images είναι ένα numpy array εικόνων στη μορφή (ύψος, πλάτος, κανάλια)\n",
        "all_images_transposed = all_images.transpose((0, 3, 1, 2))  # Αλλαγή σε μορφή (batch_size, κανάλια, ύψος, πλάτος)\n",
        "\n",
        "all_images_tensor = torch.tensor(all_images_transposed).float()\n",
        "\n",
        "# Δημιουργία ενός dataset από τους tensors\n",
        "dataset = TensorDataset(all_images_tensor, all_labels_tensor)\n",
        "\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Mεγέθη για κάθε σύνολο\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.6 * total_size)\n",
        "test_size = int(0.2 * total_size)\n",
        "validation_size = total_size - train_size - test_size\n",
        "\n",
        "# Διαίρεση του dataset σε σύνολα εκπαίδευσης, επικύρωσης και ελέγχου\n",
        "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
        "\n",
        "# Ορισμός των DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "DUz0qkpsVRdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B)**\n",
        "Για το συγκεκριμένο πρόβλημα ταξινόμησης εικόνων - ειδικά για την ανίχνευση χρήσης μάσκας σε πρόσωπα - η χρήση Συνελικτικών Νευρωνικών Δικτύων (Convolutional Neural Networks, CNNs) θεωρείται ιδανική. Τα CNNs είναι ιδιαίτερα δυνατά στην επεξεργασία εικόνων και αναγνώριση προτύπων μέσα σε αυτές, χάρη στην ικανότητά τους να εξάγουν χαρακτηριστικά από τις εικόνες με τη χρήση φίλτρων"
      ],
      "metadata": {
        "id": "KxkJ8K3sXq9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # Επίπεδο 1\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=5, padding=2),  # Αλλαγή από 1 σε 3\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        # Επίπεδο 2\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        # Πλήρως συνδεδεμένο επίπεδο\n",
        "        self.fc = nn.Linear(8*8*32, 2)  # Υποθέτοντας 2 κατηγορίες\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.flatten(out)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Δημιουργία αντικειμένου CNN\n",
        "cnn = CNN()\n"
      ],
      "metadata": {
        "id": "tcXU9VqkXs-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cnn)\n",
        "params = list(cnn.parameters())\n",
        "print(\"Number of learnable parameters' sets: \" , len(params))\n",
        "for i in params:\n",
        "  print(i.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7dMZyC5ekq1",
        "outputId": "1f835240-1426-4b99-aaf8-b6715b251ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n",
            "Number of learnable parameters' sets:  6\n",
            "torch.Size([16, 3, 5, 5])\n",
            "torch.Size([16])\n",
            "torch.Size([32, 16, 5, 5])\n",
            "torch.Size([32])\n",
            "torch.Size([2, 2048])\n",
            "torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_shapes_hook(module, input, output):\n",
        "    # Εκτύπωση του σχήματος της εξόδου κάθε επιπέδου\n",
        "    print(f\"{module.__class__.__name__} output shape: {output.shape}\")\n",
        "\n",
        "\n",
        "hook_handles = []\n",
        "for layer in cnn.children():\n",
        "    hook_handles.append(layer.register_forward_hook(print_shapes_hook))\n",
        "\n",
        "# forward pass\n",
        "input_tensor = torch.randn(1, 3, 32, 32)  # Υποθέτοντας ότι το μέγεθος εισόδου είναι (batch_size, channels, height, width), το πρώτο 1 είναι το batch size\n",
        "output = cnn(input_tensor)\n",
        "\n",
        "for handle in hook_handles:\n",
        "    handle.remove()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KtPsBarem3H",
        "outputId": "addeebad-2573-4eee-f668-49c789990b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential output shape: torch.Size([1, 16, 16, 16])\n",
            "Sequential output shape: torch.Size([1, 32, 8, 8])\n",
            "Flatten output shape: torch.Size([1, 2048])\n",
            "Linear output shape: torch.Size([1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
        "\n",
        "losses = []\n",
        "losses_in_epochs = []\n",
        "for epoch in range(num_epochs):  # Εποχές εκπαίδευσης\n",
        "    epoch_loss = 0\n",
        "    num_batches = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = Variable(images.float())\n",
        "        labels = Variable(labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = cnn(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        if (i+1) % 100 == 0:  # Εκτύπωση πληροφοριών κάθε 100 batch\n",
        "            print('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' %\n",
        "                  (epoch+1, num_epochs, i+1, len(train_loader)//batch_size, loss.item()))\n",
        "\n",
        "    # Μέση τιμή loss για την τρέχουσα εποχή\n",
        "    average_loss = epoch_loss / num_batches\n",
        "    losses_in_epochs.append(average_loss)\n",
        "\n",
        "# Σχεδιάζοντας την training loss\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(losses_in_epochs)\n",
        "plt.show()\n",
        "\n",
        "# Αξιολόγηση του μοντέλου\n",
        "cnn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "    images = Variable(images.float())\n",
        "    outputs = cnn(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "# Εκτύπωση της ακρίβειας του μοντέλου στις δοκιμαστικές εικόνες\n",
        "print('Test Accuracy of the model on the test images: %.4f %%' % (100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "JltH9-oReq6w",
        "outputId": "70ab9172-b75c-48b8-f562-086e48c3d786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the test images: 97.1223 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Στο συγκεκριμένο διάγραμμα, μπορούμε να δούμε ότι η απώλεια ξεκινά από ένα υψηλό σημείο και μειώνεται γρήγορα μετά την πρώτη εποχή. Αυτό υποδεικνύει ότι το μοντέλο μαθαίνει και βελτιώνεται σημαντικά. Μετά τις πρώτες δύο εποχές, η μείωση της απώλειας φαίνεται να επιβραδύνεται.\n",
        "\n",
        "Η καμπύλη της απώλειας επιπεδώνει καθώς πλησιάζουμε την έκτη εποχή, δείχνοντας ότι το μοντέλο έχει σταθεροποιηθεί και δεν βελτιώνεται περαιτέρω σημαντικά. Αυτό σημαίνει ότι το μοντέλο έχει φτάσει σε ένα σημείο όπου πρόσθετες εποχές εκπαίδευσης δεν προσφέρουν σημαντική βελτίωση, ή ότι χρειάζεται περαιτέρω ρύθμιση των παραμέτρων για να επιτευχθούν καλύτερα αποτελέσματα.\n",
        "\n"
      ],
      "metadata": {
        "id": "OuUauHFD2Pl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Γ)** **CNN_2**\n",
        "\n",
        "Το δεύτερο μοντέλο CNN_2 έχει μερικές προσθήκες σε σχέση με το πρώτο (CNN). Πρώτον, περιλαμβάνει ένα επιπλέον συνελικτικό επίπεδο, αυξάνοντας το σύνολο από δύο σε τρία, γεγονός που το καθιστά πιο ικανό στο να αναγνωρίζει περίπλοκα χαρακτηριστικά από τις εικόνες. Δεύτερον, σε κάθε συνελικτικό επίπεδο προστίθεται ένα επίπεδο dropout, το οποίο βοηθά στο να αποφεύγεται το overfitting , δηλαδή το μοντέλο να μην εξαρτάται πολύ από τα συγκεκριμένα δεδομένα εκπαίδευσης. Τρίτον, το CNN_2 χρησιμοποιεί περισσότερα φίλτρα στα συνελικτικά επίπεδα, γεγονός που του επιτρέπει να επεξεργάζεται καλύτερα τις εικόνες. Αυτές οι προσθήκες κάνουν το CNN_2 πιο ικανό και προσαρμοσμένο για πολύπλοκα σετ δεδομένων σε σχέση με το απλούστερο πρώτο μοντέλο."
      ],
      "metadata": {
        "id": "0uKkrbH-1GNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_2, self).__init__()\n",
        "        # Πρώτο συνελικτικό επίπεδο με dropout\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.25))  # Προσθήκη Dropout\n",
        "\n",
        "        # Δεύτερο συνελικτικό επίπεδο με dropout\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.25))  # Προσθήκη Dropout\n",
        "\n",
        "        # Τρίτο συνελικτικό επίπεδο με dropout\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # Ρύθμιση του αριθμού φίλτρων\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.25))  # Προσθήκη Dropout\n",
        "\n",
        "        # Πλήρως συνδεδεμένο επίπεδο\n",
        "        self.fc = nn.Linear(4*4*64, 2)  # Προσαρμογή των εισαγωγικών χαρακτηριστικών του πλήρως συνδεδεμένου επιπέδου\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)  # Προσθήκη του τρίτου επιπέδου στην προώθηση\n",
        "        out = self.flatten(out)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Δημιουργία αντικειμένου CNN_2\n",
        "cnn_2 = CNN_2()\n"
      ],
      "metadata": {
        "id": "IoPqfzVR1IEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cnn_2)\n",
        "params = list(cnn_2.parameters())\n",
        "print(\"Number of learnable parameters' sets: \" , len(params))\n",
        "for i in params:\n",
        "  print(i.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogsx-Se91b2g",
        "outputId": "4142bd5c-f533-4b87-a918-a0bf11da8252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_2(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Dropout(p=0.25, inplace=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Dropout(p=0.25, inplace=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Dropout(p=0.25, inplace=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n",
            "Number of learnable parameters' sets:  8\n",
            "torch.Size([16, 3, 5, 5])\n",
            "torch.Size([16])\n",
            "torch.Size([32, 16, 5, 5])\n",
            "torch.Size([32])\n",
            "torch.Size([64, 32, 3, 3])\n",
            "torch.Size([64])\n",
            "torch.Size([2, 1024])\n",
            "torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Συνάρτηση για εκτύπωση του σχήματος των επιπέδων\n",
        "def print_shapes_hook(module, input, output):\n",
        "    print(f\"{module.__class__.__name__} output shape: {output.shape}\")\n",
        "\n",
        "hook_handles = []\n",
        "for layer in cnn_2.children():\n",
        "    hook_handles.append(layer.register_forward_hook(print_shapes_hook))\n",
        "\n",
        "# forward pass\n",
        "input_tensor = torch.randn(1, 3, 32, 32)  # Υποθέτοντας ότι το μέγεθος εισόδου είναι (batch_size, channels, height, width), το πρώτο 1 είναι το batch size\n",
        "output = cnn_2(input_tensor)\n",
        "\n",
        "for handle in hook_handles:\n",
        "    handle.remove()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5nwDWH51i4_",
        "outputId": "8c6cbfe7-b687-446f-9cf0-d9c6201f5022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential output shape: torch.Size([1, 16, 16, 16])\n",
            "Sequential output shape: torch.Size([1, 32, 8, 8])\n",
            "Sequential output shape: torch.Size([1, 64, 4, 4])\n",
            "Flatten output shape: torch.Size([1, 1024])\n",
            "Linear output shape: torch.Size([1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn_2.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training\n",
        "losses = []\n",
        "losses_in_epochs = []\n",
        "for epoch in range(num_epochs):  # Επανάληψη για κάθε εποχή\n",
        "    epoch_loss = 0\n",
        "    num_batches = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = Variable(images.float())\n",
        "        labels = Variable(labels)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = cnn_2(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        if (i+1) % 100 == 0:  # Εκτύπωση πληροφοριών κάθε 100 batch\n",
        "            print('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' %\n",
        "                  (epoch+1, num_epochs, i+1, len(train_loader)//batch_size, loss.item()))\n",
        "\n",
        "    # Μέσo  loss για την τρέχουσα εποχή\n",
        "    average_loss = epoch_loss / num_batches\n",
        "    losses_in_epochs.append(average_loss)\n",
        "\n",
        "# Σχεδιάζοντας  loss\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(losses_in_epochs)\n",
        "plt.show()\n",
        "\n",
        "# Αξιολόγηση του μοντέλου\n",
        "cnn_2.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "    images = Variable(images.float())\n",
        "    outputs = cnn_2(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)  #  Εύρεση της προβλεπόμενης κλάσης\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()     #  Σύγκριση με τις πραγματικές ετικέτες και υπολογισμός σωστών προβλέψεων\n",
        "\n",
        "# Εκτύπωση της ακρίβειας του μοντέλου στις testing εικόνες\n",
        "print('Test Accuracy of the model on the test images: %.4f %%' % (100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "NCBc_p0I1oUW",
        "outputId": "654b448f-f7e1-4f94-cd56-4628194b646c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the test images: 97.3621 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Από το διάγραμμα, βλέπουμε ότι η απώλεια μειώνεται σημαντικά από την πρώτη εποχή προς την δεύτερη, υποδηλώνοντας ότι το μοντέλο έχει μάθει αποτελεσματικά από τα αρχικά στάδια της εκπαίδευσης. Μετά τις πρώτες δύο εποχές, η μείωση της απώλειας γίνεται πολύ πιο ήπια, με την καμπύλη να επιπεδώνεται. Αυτό δείχνει ότι το μοντέλο έχει φτάσει σε ένα σημείο όπου επιπλέον εκπαίδευση δεν επιφέρει σημαντικές βελτιώσεις στην απόδοσή του.\n",
        "\n"
      ],
      "metadata": {
        "id": "78_VyyMGxGhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN 3**"
      ],
      "metadata": {
        "id": "n40Q-AfSbU10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Το τρίτο μοντέλο CNN (CNN_3) χρησιμοποιεί περισσότερα φίλτρα σε κάθε συνελικτικό επίπεδο, γεγονός που του επιτρέπει να αναγνωρίζει πιο λεπτομερή χαρακτηριστικά από τις εικόνες. Έχει επίσης ενσωματωμένο batch normalization σε κάθε επίπεδο, βελτιώνοντας την εκπαίδευση και τη σταθερότητα του δικτύου. Το μοντέλο χρησιμοποιεί αυξημένα ποσοστά dropout για να μειώσει τον κίνδυνο overfitting. Επιπρόσθετα, το CNN_3 περιλαμβάνει ένα τέταρτο συνελικτικό επίπεδο για ακόμα πιο βαθιά ανάλυση και δύο πλήρως συνδεδεμένα επίπεδα, προσθέτοντας περισσότερη επεξεργαστική ικανότητα."
      ],
      "metadata": {
        "id": "fv3GyFf-jkSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_3, self).__init__()\n",
        "        # Πρώτο συνελικτικό επίπεδο με αύξηση φίλτρων και dropout\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Αύξηση του αριθμού φίλτρων\n",
        "            nn.BatchNorm2d(32),  # Προσθήκη batch normalization\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.3))  # Αύξηση του ποσοστού dropout\n",
        "\n",
        "        # Δεύτερο συνελικτικό επίπεδο με αύξηση φίλτρων και dropout\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # Αύξηση του αριθμού φίλτρων\n",
        "            nn.BatchNorm2d(64),  # Προσθήκη batch normalization\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.3))  # Αύξηση του ποσοστού dropout\n",
        "\n",
        "        # Τρίτο συνελικτικό επίπεδο με αύξηση φίλτρων και dropout\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # Αύξηση του αριθμού φίλτρων\n",
        "            nn.BatchNorm2d(128),  # Προσθήκη batch normalization\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.4))  # Αύξηση του ποσοστού dropout\n",
        "\n",
        "        # Προσθήκη τέταρτου συνελικτικού επιπέδου\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),  # Αύξηση του αριθμού φίλτρων\n",
        "            nn.BatchNorm2d(256),  # Προσθήκη batch normalization\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.5))  # Αύξηση του ποσοστού dropout\n",
        "\n",
        "        # Προσθήκη επιπλέον πλήρως συνδεδεμένων επιπέδων\n",
        "        self.fc1 = nn.Linear(2*2*256, 1024)  # Προσθήκη ενός επιπλέον πλήρως συνδεδεμένου επιπέδου\n",
        "        self.fc2 = nn.Linear(1024, 2)  # Προσαρμογή του τελικού εξόδου σε 2 κλάσεις\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.flatten(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Δημιουργία αντικειμένου του CNN_3\n",
        "cnn_3 = CNN_3()"
      ],
      "metadata": {
        "id": "7a39sSbnbT2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cnn_3)\n",
        "params = list(cnn_3.parameters())\n",
        "print(\"Number of learnable parameters' sets: \" , len(params))\n",
        "for i in params:\n",
        "  print(i.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW2wpk0dbdMs",
        "outputId": "00e157ff-4979-4416-e88c-d1e5fd066422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_3(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Dropout(p=0.3, inplace=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Dropout(p=0.4, inplace=False)\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n",
            "Number of learnable parameters' sets:  20\n",
            "torch.Size([32, 3, 3, 3])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "torch.Size([64, 32, 3, 3])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n",
            "torch.Size([128, 64, 3, 3])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([256, 128, 3, 3])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([1024, 1024])\n",
            "torch.Size([1024])\n",
            "torch.Size([2, 1024])\n",
            "torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn_3 .parameters(), lr=learning_rate)\n",
        "\n",
        "# Training\n",
        "losses = []\n",
        "losses_in_epochs = []\n",
        "for epoch in range(num_epochs):  # Επανάληψη για κάθε εποχή\n",
        "    epoch_loss = 0\n",
        "    num_batches = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = Variable(images.float())\n",
        "        labels = Variable(labels)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = cnn_3(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        if (i+1) % 100 == 0:  # Εκτύπωση πληροφοριών κάθε 100 batch\n",
        "            print('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' %\n",
        "                  (epoch+1, num_epochs, i+1, len(train_loader)//batch_size, loss.item()))\n",
        "\n",
        "    # Μέσο loss για την τρέχουσα εποχή\n",
        "    average_loss = epoch_loss / num_batches\n",
        "    losses_in_epochs.append(average_loss)\n",
        "\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(losses_in_epochs)\n",
        "plt.show()\n",
        "\n",
        "# Αξιολόγηση του μοντέλου\n",
        "cnn_3.eval()  # Ορισμός του μοντέλου σε λειτουργία αξιολόγησης\n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "    images = Variable(images.float())\n",
        "    outputs = cnn_3(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)  # Εύρεση της προβλεπόμενης κλάσης\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()  # Σύγκριση με τις πραγματικές ετικέτες και υπολογισμός σωστών προβλέψεων\n",
        "\n",
        "# Εκτύπωση της ακρίβειας του μοντέλου στις testing εικόνες\n",
        "print('Test Accuracy of the model on the test images: %.4f %%' % (100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "HORE7vnxbhHM",
        "outputId": "ac103194-9370-466d-8a7e-eb9ea1c1aa5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the test images: 96.8825 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Η απώλεια είναι σχετικά χαμηλή από την αρχή, ξεκινώντας κάτω από 0.8 και μειώνεται γρήγορα κατά την πρώτη εποχή. Στη συνέχεια, η μείωση της απώλειας συνεχίζεται με πιο ήπιο ρυθμό και μια ομαλότερη καμπύλη μέχρι το τέλος των εποχών που παρουσιάζονται.\n",
        "\n"
      ],
      "metadata": {
        "id": "p39Xjv2MyNge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Το πρώτο διάγραμμα ξεκινά με μια απώλεια περίπου 3.5 και πέφτει κατακόρυφα σε μια απώλεια κοντά στο 0 μετά από περίπου δύο εποχές. Το δεύτερο διάγραμμα ξεκινάει επίσης με υψηλή απώλεια περίπου 2.5 και πέφτει γρήγορα κάτω από 0.5 μετά την πρώτη εποχή, ενώ το τρίτο διάγραμμα έχει τη χαμηλότερη αρχική απώλεια περίπου 0.5 και μειώνεται σταθερά προς το 0.\n",
        "\n",
        "Για να κρίνουμε ποιο διάγραμμα αντιπροσωπεύει το \"καλύτερο\" μοντέλο, πρέπει να λάβουμε υπόψη την απόλυτη τιμή της απώλειας καθώς και το πόσο γρήγορα και σταθερά μειώνεται αυτή με την πάροδο των εποχών. Το τρίτο διάγραμμα έχει τη χαμηλότερη αρχική απώλεια και διατηρεί μια σχετικά σταθερή μείωση, που σημαίνει πιο σταθερή εκπαίδευση και καλύτερη γενικευτική ικανότητα. Ωστόσο, το δεύτερο διάγραμμα φαίνεται να είναι εκείνο με την πιο μεγάλη βελτίωση από πολύ υψηλή απώλεια σε πολύ χαμηλή, που επίσης υποδεικνύει ένα ισχυρό μοντέλο εφόσον η χαμηλή απώλεια συντηρείται και σε νέα δεδομένα.\n",
        "Άρα θεωρούμε το δεύτερο μοντέλο ως καλύτερο."
      ],
      "metadata": {
        "id": "WQIJbDaidS0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Συλλέγουμε τις ετικέτες και τις προβλέψεις\n",
        "y_true = []\n",
        "y_scores = []\n",
        "best_cnn = cnn_2#  Δεύτερο μοντέλο\n",
        "\n",
        "best_cnn.eval()\n",
        "with torch.no_grad():  # Απενεργοποιούμε τους υπολογισμούς των gradients\n",
        "    for images, labels in test_loader:\n",
        "        images = images.float()\n",
        "        outputs = best_cnn(images)\n",
        "        #print(outputs)\n",
        "        probabilities = torch.softmax(outputs, dim=1)[:, 1]  # Πιθανότητες για την κλάση χωρις μασκα\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_scores.extend(probabilities.detach().numpy())\n",
        "\n",
        "# Υπολογισμός της καμπύλης precision-recall και του AUC\n",
        "precision, recall,thresholds_pr = precision_recall_curve(y_true, y_scores)\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# Εκτύπωση του AUC\n",
        "print(f'Precision-Recall AUC: {pr_auc}')\n",
        "\n",
        "# Σχεδίαση της καμπύλης precision-recall\n",
        "plt.figure()\n",
        "plt.plot(recall, precision, label=f'Precision-Recall curve (AUC = {pr_auc:.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Επιπλέον, αν θέλετε να υπολογίσετε και την καμπύλη ROC\n",
        "fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Εκτύπωση του ROC AUC\n",
        "print(f'ROC AUC: {roc_auc}')\n",
        "\n",
        "# Σχεδίαση της καμπύλης ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "VHw1LX7Be0YP",
        "outputId": "47f4bac6-90fe-48c4-c2c7-681686969544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision-Recall AUC: 0.9933210390351699\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC: 0.9893264630106736\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**ROC Curve:**\n",
        "\n",
        "Η ROC Curve δείχνει τη σχέση μεταξύ του True Positive Rate (TPR) και του False Positive Rate (FPR) σε διάφορα κατώφλια ταξινόμησης. Μια τέλεια ταξινόμηση θα είχε μια ROC Curve που θα έφτανε στην πάνω αριστερή γωνία (TPR = 1, FPR = 0), που σημαίνει 100% ευαισθησία (sensitivity) χωρίς κανένα λάθος θετικό (false positives).\n",
        "\n",
        "Το διάγραμμα που βλέπουμε έχει AUC (Area Under the Curve) ίσο με 1, το οποίο υποδηλώνει τέλεια απόδοση του ταξινομητή.\n",
        "\n",
        "**Precision-Recall Curve:**\n",
        "\n",
        "Η Precision-Recall Curve δείχνει τη σχέση μεταξύ της ακρίβειας (precision) και της ανάκλησης (recall). Η ακρίβεια είναι η πιθανότητα οι προβλέψεις που έχουν καταταγεί ως θετικές να είναι πραγματικά θετικές, ενώ η ανάκληση είναι η πιθανότητα να εντοπίσουμε όλες τις πραγματικές θετικές περιπτώσεις.\n",
        "Το διάγραμμα δείχνει πάλι ένα AUC ίσο με 1, το οποίο είναι το τέλειο σκορ και μπορεί να είναι αποτέλεσμα των ίδιων συνθηκών που αναφέρθηκαν προηγουμένως.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "43jsYVDUfwut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**δ)**\n",
        "\n",
        "\n",
        "Αρχικά, φορτώνουμε το dataset με τις εικόνες, στις οποίες οι μάσκες είναι φορεμένες λάθος.Στη συνέχεια, για να υπολογίσουμε το ποσοστό των εικόνων που έχουν ταξινομηθεί σε λάθος κλάση, δηλαδή σε αυτή που οι άνθρωποι φοράνε μάσκα, τρέχουμε τις εικόνες του dataset με το καλύτερο μοντέλο.\n",
        "\n",
        "Για να μπορέσουμε έπειτα να μειώσουμε αυτό το ποσοστό, πρέπει να κάνουμε το μοντέλο πιο ευαίσθητο στη κλάση \"χωρίς μάσκα\", καθώς σε αυτή θα ταξινομηθούν οι εικόνες με λάθος χρήση μάσκα. Με βάση το διάγραμμα recall επέλεξα ένα threshold που μεγιστοποιεί τη τιμή recall για τη κλάση \"χωρίς μάσκα\".Αν η πρόβλεψη είναι πάνω από το threshold τότε θα ανήκει το δείγμα στη κλάση \"χωρίς μάσκα\". Με την επιλογή αυτού του threshold επιτυγχάνουμε καλύτερο recall και έτσι μειώνουμε τον αριθμό των false negatives, δηλαδή τις περιπτώσεις που το μοντέλο  ταξινομεί τα δείγματα της κλάσης \"χωρίς μάσκα\" στη κλάση \"με μάσκα\".Η τεχνική αυτή βοηθάει στο να ταξινομηθούν σωστά οι εικόνες που οι μάσκες έχουν τοποθετηθεί λανθασμένα, καθώς πλεον το μοντέλο επικεντρώνεται περισσότερο στο να εντοπίζει τις περιπτώσεις \"χωρίς μάσκα\".\n",
        "\n",
        "**ΔΟΚΙΜΕΣ threshold**\n",
        "\n",
        "Στην αρχή όταν πήρα το threshold που μεγιστοποιούσε τη recall, δηλαδή το threshold_pr[0], ενώ μηδένισε το ποσοστό των εσφαλμένων ταξινομήσεων, στο test set του μοντέλου δεν λειτούργησε καλά, καθώς το test accuracy έπεσε περίπου στο 50%. Αυτό συνέβη διότι προσπαθώντας να αυξήσω τη πιθανότητα να ταξινομηθεί μία εικόνα ως εικόνα χωρίς μάσκα, μείωνα ταυτόχρονα τη πιθανότητα να ταξινομηθεί στην κλάση με μάσκα. Υπάρχει ένα trade off μεταξύ recall και presicion. Οπότε δοκίμασα και άλλες τιμές του threshold και κατέληξα στο thresholds_pr[max_recall_index + 160]. Με αυτό το  threshold, όπως παρατηρούμε παρακάτω, η τιμή του ποσοστού εσφαλμένων ταξινομήσεων πάλι είναι ελάχιστη και η ακρίβεια του μοντέλου γενικά κρατήθηκε σε μία καλή ακρίβεια.\n",
        "\n"
      ],
      "metadata": {
        "id": "ugvD5H-cz0GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask_incorrect_use_images, _ = load_images_from_folder('/content/final/mask_incorrect_use')\n",
        "mask_incorrect_use_images_np = np.array(mask_incorrect_use_images)\n",
        "mask_incorrect_use_images = mask_incorrect_use_images_np.transpose((0, 3, 1, 2))  # Αλλαγή στη μορφή (batch_size, channels, height, width)\n",
        "\n",
        "mask_incorrect_use_images_tensor = torch.tensor(mask_incorrect_use_images).float()\n"
      ],
      "metadata": {
        "id": "U2YJ6cImgCQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Θέτουμε το μοντέλο σε λειτουργία αξιολόγησης\n",
        "\n",
        "best_cnn.eval()\n",
        "# Απενεργοποιούμε τους υπολογισμούς των gradients για την αξιολόγηση\n",
        "with torch.no_grad():\n",
        "    # Προβλέψεις του μοντέλου\n",
        "    outputs = best_cnn(mask_incorrect_use_images_tensor)\n",
        "\n",
        "    # Υπολογισμός της κλάσης με την υψηλότερη πιθανότητα\n",
        "    _, predicted_classes = torch.max(outputs, 1)\n",
        "\n",
        "print(predicted_classes)\n",
        "# Υπολογισμός του ποσοστού των εικόνων που ταξινομούνται εσφαλμένα ως \"αποδεκτή χρήση μάσκας\"\n",
        "incorrectly_classified = (predicted_classes == 0).sum().item()  # Υποθέτουμε ότι η κλάση 0 είναι \"με μάσκα\"\n",
        "total_images = mask_incorrect_use_images_tensor.size(0)\n",
        "\n",
        "# Ποσοστό λανθασμένης ταξινόμησης\n",
        "percentage_incorrectly_classified = (incorrectly_classified / total_images) * 100\n",
        "\n",
        "print(f\"Ποσοστό εσφαλμένης ταξινόμησης ως 'αποδεκτή χρήση μάσκας': {percentage_incorrectly_classified:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4do0Fp7yCmB",
        "outputId": "2efd27ad-e8d4-43c9-828f-2d232f52ad33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
            "        0, 1, 1, 0, 1, 0, 1, 1])\n",
            "Ποσοστό εσφαλμένης ταξινόμησης ως 'αποδεκτή χρήση μάσκας': 19.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_recall_index = np.argmax(recall)\n",
        "#print(thresholds_pr)\n",
        "selected_threshold = thresholds_pr[max_recall_index + 160]\n",
        "\n",
        "\n",
        "# Εκτυπώνουμε το threshold που δίνει το υψηλότερo recall\n",
        "print(f\"Το threshold που μεγιστοποιεί τη recall για τη κλάση χωρίς μάσκα είναι: {selected_threshold}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tazQIJkJ7nOf",
        "outputId": "39351362-c22a-480f-c333-7164ea0dd83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Το threshold που μεγιστοποιεί τη recall για τη κλάση χωρίς μάσκα είναι: 0.013076506555080414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = selected_threshold # threshold  για την κλάση \"χωρίς μάσκα\"\n",
        "\n",
        "# Υποθέτουμε ότι οι προβλέψεις του μοντέλου επιστρέφονται σε μορφή softmax probabilities\n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs = best_cnn(mask_incorrect_use_images_tensor)\n",
        "    probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "    # Υπολογίζουμε τις προβλεπόμενες κλάσεις με βάση το κατώφλι\n",
        "    predicted_classes = (probabilities[:, 1] >= threshold).long()  # Κλάση 1 εάν η πιθανότητα είναι >= threshold\n",
        "\n",
        "print(predicted_classes)\n",
        "# Υπολογισμός του ποσοστού των εικόνων που ταξινομούνται εσφαλμένα\n",
        "incorrectly_classified = (predicted_classes == 0).sum().item() # Υποθέτουμε ότι η κλάση 0 είναι \"με μάσκα\"\n",
        "total_images = mask_incorrect_use_images_tensor.size(0)\n",
        "\n",
        "# Ποσοστό λανθασμένης ταξινόμησης\n",
        "percentage_incorrectly_classified = (incorrectly_classified / total_images) * 100\n",
        "\n",
        "print(f\"Ποσοστό εσφαλμένης ταξινόμησης ως 'αποδεκτή χρήση μάσκας': {percentage_incorrectly_classified:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mazvTT8_kGxi",
        "outputId": "49951c03-f461-48f6-d572-b27aff441e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 1, 1, 1, 1, 0, 1, 1])\n",
            "Ποσοστό εσφαλμένης ταξινόμησης ως 'αποδεκτή χρήση μάσκας': 5.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Παρατηρούμε ότι το ποσοστό εσφαλμένης ταξινόμηση ως 'αποδεκτή χρήση μάσκας' έχει μειωθεί κατα πολύ. Μπορούμε να δούμε από το tensor με τα labels ότι τα περισσότερα labels ανήκουν στη σωστή κλάση, όπως ήταν αναμενόμενο."
      ],
      "metadata": {
        "id": "MtBGJ3sZ1xxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Αξιολόγηση του μοντέλου\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "cnn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "    images = Variable(images.float())\n",
        "    outputs = cnn(images)\n",
        "    # Εφαρμογή softmax για μετατροπή σε πιθανότητες\n",
        "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "    # Επιλογή της κλάσης με βάση το threshold\n",
        "    predicted = (probabilities[:, 1] > threshold).long()  # Κλάση 1 (χωρίς μάσκα) εάν η πιθανότητα > threshold\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "# Εκτύπωση της ακρίβειας του μοντέλου στις testing εικόνες\n",
        "print('Test Accuracy του μοντέλου στις test εικόνες: %.4f %%' % (100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPncSCVv6J4R",
        "outputId": "919e09e8-7d3a-4027-e28e-0ef4b66125f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy του μοντέλου στις test εικόνες: 90.6475 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ΔΙΑΓΡΑΜΜΑ ΑΡΧΙΤΕΚΤΟΝΙΚΗΣ του καλύτερου μοντέλου για το powerpoint**"
      ],
      "metadata": {
        "id": "eDjd2D3WhzA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgS000HVf6if",
        "outputId": "fe3b327d-c5c1-4e6a-955b-0714034f7f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.1.0+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4131 sha256=33cd0d91de6e1aee46d5c25e3eb2021600bf7e8b349948acc38a2bf4611fa1cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "\n",
        "sample_input = torch.randn(1,3, 32, 32)\n",
        "model_output = cnn_2(sample_input)\n",
        "make_dot(model_output, params=dict(list(cnn_2.named_parameters()))).render(\"cnn_architecture\", format=\"png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6ZX7vg-RfusS",
        "outputId": "368888a2-99c7-4f2b-849d-0708ee966b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cnn_architecture.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ΜΕΡΟΣ Β**"
      ],
      "metadata": {
        "id": "v1xx4HIHBR_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p \"/content/final_2\"\n",
        "!unzip -q \"/content/drive/My Drive/final_project_protupa/Data_Receptors.zip\" -d \"/content/final_2\""
      ],
      "metadata": {
        "id": "qqyPL8MhBnWQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2d17e03-25b4-4d73-f916-93de1d23cb72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE as smt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "metadata": {
        "id": "m5mh9p3cDKeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ορίσμος του seed\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Διαβάστε τα δεδομένα από ένα αρχείο CSV\n",
        "data = pd.read_csv('/content/final_2/Train_Features.csv', header=None).to_numpy()\n",
        "labels = pd.read_csv('/content/final_2/Train_Labels.csv', header=None).to_numpy()\n",
        "\n",
        "# Μετατροπή των δεδομένων σε numpy arrays\n",
        "data = data.astype(np.float32)\n",
        "labels = labels.astype(np.long)\n",
        "\n",
        "smote = smt(sampling_strategy = 'minority', random_state = 42)\n",
        "data_new , labels_new = smote.fit_resample(data, labels)\n",
        "\n",
        "# Διαχωρισμός των δεδομένων σε εκπαίδευση και επικύρωση\n",
        "X_train, X_val, y_train, y_val = train_test_split(data_new, labels_new, test_size=0.2, random_state=seed)\n",
        "\n",
        "# Κανονικοποίηση δεδομένων\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# Μετατροπή των δεδομένων σε tensors του PyTorch\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "# Μετατρέπουμε το y_train_tensor σε 1D tensor\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long).view(-1)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.long).view(-1)"
      ],
      "metadata": {
        "id": "p0xnwZW2CcIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f909be4-c9ee-4f30-a2fa-08f6a252c5e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-ce3532358b8c>:12: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  labels = labels.astype(np.long)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTE METHOD**\n",
        "\n",
        "Χρησιμοποιήσαμε τη μέθοδο SMOTE για να αντιμετωπίσει το πρόβλημα της ανισορροπίας κλάσεων σε ένα πρόβλημα ταξινόμησης, καθώς η κλάση 1 έχει περισσότερα δείγματα. Η μέθοδος SMOTE λύνει αυτό το πρόβλημα δημιουργώντας συνθετικά δείγματα για τη λιγότερο αντιπροσωπευτική κλάση. Τα συνθετικά δείγματα δημιουργούνται με βάση τα υπάρχοντα παραδείγματα της κλάσης, προσθέτοντας τυχαία παραδείγματα μεταξύ τους. Αυτή η διαδικασία ενισχύει τον αριθμό των παραδειγμάτων στη λιγότερο αντιπροσωπευτική κλάση, βελτιώνοντας την απόδοση του μοντέλου ταξινόμησης σε αυτήν την κλάση."
      ],
      "metadata": {
        "id": "AN2inkGylim7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Η Singular Value Decomposition **(SVD)** είναι μια τεχνική στη γραμμική άλγεβρα που χρησιμοποιείται στη μείωση διαστάσεων, ενίσχυση αποδοτικότητας αλγορίθμων, και κατανόηση σημαντικών χαρακτηριστικών στα δεδομένα. Μέσω της SVD, μπορούμε να απλοποιήσουμε τα δεδομένα διατηρώντας την περισσότερη πληροφορία, να βελτιώσουμε την απόδοση των μοντέλων μηχανικής μάθησης, να διευκολύνουμε την οπτικοποίηση και να ανακαλύψουμε πολύτιμες πληροφορίες.Εδώ τη χρησιμοποιήσαμε διότι έχουμε περισσότερα features από ότι δεδομένα. Μετά τον υπολογισμό, θα βρούμε το μέγιστο πλήθος διαστάσεων που μπορεί να φτάσει ο autoencoder χωρίς να χαθεί σημαντική πληροφορία."
      ],
      "metadata": {
        "id": "SfFR7hHNSE7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Υπολογισμός του SVD\n",
        "U, Sigma, VT = np.linalg.svd(X_train_tensor, full_matrices=False)\n",
        "\n",
        "# Υπολογισμός συνολικής ενέργειας των ιδιοτιμών\n",
        "cumulative_energy = np.cumsum(Sigma**2) / np.sum(Sigma**2)\n",
        "\n",
        "# Εύρεση του αριθμού διαστάσεων για να καλύψουμε το 95% της συνολικής διακύμανσης\n",
        "num_components = np.argmax(cumulative_energy >= 0.95) + 1  # Προσθέτουμε 1 επειδή οι δείκτες στην Python ξεκινούν από 0\n",
        "\n",
        "num_components, cumulative_energy[num_components-1]  # επιστρέφει τον αριθμό διαστάσεων και την καλυπτόμενη διακύμανση\n"
      ],
      "metadata": {
        "id": "9LkZanWAOoXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a470a814-e083-4527-e8cb-71ad5aed8cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(147, 0.95025617)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Στο συγκεκριμένο πρόβλημα πρόβλεψης του βαθμού πρόσδεσης χημικών μορίων σε βιολογικούς υποδοχείς, η χρήση του autoencoder μπορεί να έχει τα εξής οφέλη:\n",
        "\n",
        " Ο autoencoder μπορεί να εκπαιδευτεί να αναπαριστά τα χημικά μόρια σε έναν χώρο χαμηλής διάστασης, αντλώντας τα σημαντικά χαρακτηριστικά που επηρεάζουν την πρόσδεση. Αυτό μπορεί να βοηθήσει στην ανακάλυψη των κύριων παραγόντων που επηρεάζουν την αλληλεπίδραση μεταξύ των μορίων.\n",
        "\n",
        "Επίσης, τα χαρακτηριστικά χαμηλής διάστασης που παράγονται από τον autoencoder μπορούν να χρησιμοποιηθούν ως είσοδος σε μοντέλα πρόβλεψης προσδέσεων. Αυτό μειώνει τον αριθμό των χαρακτηριστικών που πρέπει να διαχειριστούμε στο τελικό μοντέλο πρόβλεψης, μειώνοντας τον υπολογιστικό φόρτο και τον χρόνο εκπαίδευσης.\n",
        "\n",
        "Παράλληλα, βελτιώνεται η απόδοση του μοντέλου, καθώς τα χαρακτηριστικά χαμηλής διάστασης μπορούν να είναι περισσότερο αποτελεσματικά στην πρόβλεψη του βαθμού πρόσδεσης, καθώς είναι πιο ενημερωμένοι και εστιάζουν στα σημαντικά χαρακτηριστικά.\n",
        "\n",
        "Γενικά, η χρήση ενός autoencoder μπορεί να βελτιώσει την απόδοση του μοντέλου σας στο πρόβλημα πρόβλεψης του βαθμού πρόσδεσης, κάνοντας την ανάλυση και την προεπεξεργασία των χημικών δεδομένων πιο αποτελεσματική και ακριβή."
      ],
      "metadata": {
        "id": "WdTPGff8HPnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Καθορίζουμε την συσκευή (GPU εάν είναι διαθέσιμη, αλλιώς CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_size, encoding_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Κωδικοποιητής\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_size, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, encoding_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Αποκωδικοποιητής\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoding_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, input_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Συνάρτηση προώθησης: Κωδικοποιεί και αποκωδικοποιεί τα δεδομένα\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "    def encode(self, x):\n",
        "        # Συνάρτηση για την επιστροφή των encoded χαρακτηριστικών\n",
        "        return self.encoder(x)\n",
        "\n",
        "\n",
        "# Εκπαίδευση του Autoencoder\n",
        "input_size = X_train.shape[1]\n",
        "latent_size = num_components  # Μέγεθος της κρυφής αναπαράστασης\n",
        "batch_size = int(num_components) # Μέγεθος δείγματος\n",
        "learning_rate = 0.001  # Ρυθμός μάθησης\n",
        "num_epochs = 200  # Αριθμός εποχών\n",
        "\n",
        "# Δημιουργία του Dataset και DataLoader\n",
        "train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(X_train, dtype=torch.float32))\n",
        "train_loader_lab = DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle=True, pin_memory=True)\n",
        "\n",
        "# Αρχικοποίηση του autoencoder και μεταφορά του στην καθορισμένη συσκευή\n",
        "model_auto = Autoencoder(input_size, latent_size).to(device)\n",
        "\n",
        "# Ορισμός της συνάρτησης απώλειας και του βελτιστοποιητή\n",
        "criterion = nn.MSELoss()  # Η MSE είναι η τυπική συνάρτηση απώλειας\n",
        "optimizer = optim.Adam(model_auto.parameters(), lr=learning_rate)  # Adam βελτιστοποιητής\n",
        "\n",
        "# Εκπαίδευση του Autoencoder\n",
        "for epoch in range(num_epochs):\n",
        "    for data in train_loader_lab:\n",
        "        inputs, _ = data\n",
        "        inputs = inputs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_auto(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "id": "qIHwdqlJGSYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7bcbe64-988e-4aae-c586-ca9031bef21f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/200], Loss: 1.0669\n",
            "Epoch [2/200], Loss: 0.9006\n",
            "Epoch [3/200], Loss: 0.8586\n",
            "Epoch [4/200], Loss: 0.9815\n",
            "Epoch [5/200], Loss: 0.8101\n",
            "Epoch [6/200], Loss: 1.1281\n",
            "Epoch [7/200], Loss: 0.7332\n",
            "Epoch [8/200], Loss: 0.8696\n",
            "Epoch [9/200], Loss: 0.9578\n",
            "Epoch [10/200], Loss: 0.7833\n",
            "Epoch [11/200], Loss: 0.8519\n",
            "Epoch [12/200], Loss: 0.8483\n",
            "Epoch [13/200], Loss: 0.8508\n",
            "Epoch [14/200], Loss: 0.9142\n",
            "Epoch [15/200], Loss: 1.3768\n",
            "Epoch [16/200], Loss: 1.0338\n",
            "Epoch [17/200], Loss: 0.9593\n",
            "Epoch [18/200], Loss: 1.0640\n",
            "Epoch [19/200], Loss: 0.9341\n",
            "Epoch [20/200], Loss: 1.0151\n",
            "Epoch [21/200], Loss: 0.9258\n",
            "Epoch [22/200], Loss: 1.1082\n",
            "Epoch [23/200], Loss: 1.0373\n",
            "Epoch [24/200], Loss: 1.1262\n",
            "Epoch [25/200], Loss: 1.0304\n",
            "Epoch [26/200], Loss: 1.1785\n",
            "Epoch [27/200], Loss: 0.9216\n",
            "Epoch [28/200], Loss: 0.9522\n",
            "Epoch [29/200], Loss: 1.1673\n",
            "Epoch [30/200], Loss: 1.0018\n",
            "Epoch [31/200], Loss: 0.9165\n",
            "Epoch [32/200], Loss: 1.1838\n",
            "Epoch [33/200], Loss: 0.8706\n",
            "Epoch [34/200], Loss: 0.7002\n",
            "Epoch [35/200], Loss: 0.5842\n",
            "Epoch [36/200], Loss: 0.9745\n",
            "Epoch [37/200], Loss: 0.8227\n",
            "Epoch [38/200], Loss: 0.6867\n",
            "Epoch [39/200], Loss: 0.5956\n",
            "Epoch [40/200], Loss: 0.6538\n",
            "Epoch [41/200], Loss: 0.5666\n",
            "Epoch [42/200], Loss: 0.6275\n",
            "Epoch [43/200], Loss: 0.7354\n",
            "Epoch [44/200], Loss: 1.0075\n",
            "Epoch [45/200], Loss: 0.7285\n",
            "Epoch [46/200], Loss: 0.6950\n",
            "Epoch [47/200], Loss: 0.8143\n",
            "Epoch [48/200], Loss: 0.7822\n",
            "Epoch [49/200], Loss: 0.6329\n",
            "Epoch [50/200], Loss: 0.6644\n",
            "Epoch [51/200], Loss: 0.8823\n",
            "Epoch [52/200], Loss: 0.5870\n",
            "Epoch [53/200], Loss: 0.6547\n",
            "Epoch [54/200], Loss: 0.6361\n",
            "Epoch [55/200], Loss: 0.6752\n",
            "Epoch [56/200], Loss: 0.6966\n",
            "Epoch [57/200], Loss: 0.7699\n",
            "Epoch [58/200], Loss: 0.5634\n",
            "Epoch [59/200], Loss: 0.6979\n",
            "Epoch [60/200], Loss: 0.5885\n",
            "Epoch [61/200], Loss: 0.6982\n",
            "Epoch [62/200], Loss: 0.6287\n",
            "Epoch [63/200], Loss: 0.5691\n",
            "Epoch [64/200], Loss: 0.9213\n",
            "Epoch [65/200], Loss: 0.6870\n",
            "Epoch [66/200], Loss: 0.6433\n",
            "Epoch [67/200], Loss: 0.7007\n",
            "Epoch [68/200], Loss: 0.8892\n",
            "Epoch [69/200], Loss: 0.6823\n",
            "Epoch [70/200], Loss: 0.7818\n",
            "Epoch [71/200], Loss: 0.5295\n",
            "Epoch [72/200], Loss: 1.0917\n",
            "Epoch [73/200], Loss: 0.5154\n",
            "Epoch [74/200], Loss: 0.6616\n",
            "Epoch [75/200], Loss: 0.8032\n",
            "Epoch [76/200], Loss: 0.7417\n",
            "Epoch [77/200], Loss: 0.6438\n",
            "Epoch [78/200], Loss: 0.6382\n",
            "Epoch [79/200], Loss: 0.7849\n",
            "Epoch [80/200], Loss: 0.7449\n",
            "Epoch [81/200], Loss: 0.7434\n",
            "Epoch [82/200], Loss: 0.7165\n",
            "Epoch [83/200], Loss: 0.9219\n",
            "Epoch [84/200], Loss: 0.4830\n",
            "Epoch [85/200], Loss: 0.6378\n",
            "Epoch [86/200], Loss: 0.7091\n",
            "Epoch [87/200], Loss: 0.6799\n",
            "Epoch [88/200], Loss: 0.7872\n",
            "Epoch [89/200], Loss: 0.8274\n",
            "Epoch [90/200], Loss: 0.7362\n",
            "Epoch [91/200], Loss: 0.7485\n",
            "Epoch [92/200], Loss: 0.6424\n",
            "Epoch [93/200], Loss: 0.5549\n",
            "Epoch [94/200], Loss: 0.7481\n",
            "Epoch [95/200], Loss: 0.5507\n",
            "Epoch [96/200], Loss: 0.5355\n",
            "Epoch [97/200], Loss: 0.5677\n",
            "Epoch [98/200], Loss: 0.6394\n",
            "Epoch [99/200], Loss: 0.8915\n",
            "Epoch [100/200], Loss: 0.9793\n",
            "Epoch [101/200], Loss: 0.8580\n",
            "Epoch [102/200], Loss: 0.9019\n",
            "Epoch [103/200], Loss: 0.7826\n",
            "Epoch [104/200], Loss: 0.6430\n",
            "Epoch [105/200], Loss: 0.8142\n",
            "Epoch [106/200], Loss: 0.5480\n",
            "Epoch [107/200], Loss: 0.6046\n",
            "Epoch [108/200], Loss: 0.6346\n",
            "Epoch [109/200], Loss: 0.5818\n",
            "Epoch [110/200], Loss: 0.6314\n",
            "Epoch [111/200], Loss: 0.6083\n",
            "Epoch [112/200], Loss: 0.5978\n",
            "Epoch [113/200], Loss: 0.6399\n",
            "Epoch [114/200], Loss: 1.1569\n",
            "Epoch [115/200], Loss: 0.4937\n",
            "Epoch [116/200], Loss: 0.8387\n",
            "Epoch [117/200], Loss: 0.6063\n",
            "Epoch [118/200], Loss: 0.7079\n",
            "Epoch [119/200], Loss: 0.6683\n",
            "Epoch [120/200], Loss: 0.5475\n",
            "Epoch [121/200], Loss: 0.6898\n",
            "Epoch [122/200], Loss: 0.5816\n",
            "Epoch [123/200], Loss: 0.8210\n",
            "Epoch [124/200], Loss: 0.7836\n",
            "Epoch [125/200], Loss: 0.5807\n",
            "Epoch [126/200], Loss: 0.5108\n",
            "Epoch [127/200], Loss: 0.6327\n",
            "Epoch [128/200], Loss: 0.9331\n",
            "Epoch [129/200], Loss: 0.5786\n",
            "Epoch [130/200], Loss: 0.5999\n",
            "Epoch [131/200], Loss: 0.7694\n",
            "Epoch [132/200], Loss: 0.6843\n",
            "Epoch [133/200], Loss: 0.8268\n",
            "Epoch [134/200], Loss: 0.6027\n",
            "Epoch [135/200], Loss: 0.6195\n",
            "Epoch [136/200], Loss: 0.8179\n",
            "Epoch [137/200], Loss: 0.5798\n",
            "Epoch [138/200], Loss: 0.5646\n",
            "Epoch [139/200], Loss: 0.7797\n",
            "Epoch [140/200], Loss: 1.0191\n",
            "Epoch [141/200], Loss: 0.8389\n",
            "Epoch [142/200], Loss: 0.5945\n",
            "Epoch [143/200], Loss: 0.8842\n",
            "Epoch [144/200], Loss: 0.7787\n",
            "Epoch [145/200], Loss: 0.8217\n",
            "Epoch [146/200], Loss: 0.6677\n",
            "Epoch [147/200], Loss: 0.8138\n",
            "Epoch [148/200], Loss: 0.5966\n",
            "Epoch [149/200], Loss: 0.5013\n",
            "Epoch [150/200], Loss: 0.7618\n",
            "Epoch [151/200], Loss: 1.0073\n",
            "Epoch [152/200], Loss: 0.7926\n",
            "Epoch [153/200], Loss: 1.0502\n",
            "Epoch [154/200], Loss: 0.5300\n",
            "Epoch [155/200], Loss: 0.7680\n",
            "Epoch [156/200], Loss: 0.4968\n",
            "Epoch [157/200], Loss: 0.6367\n",
            "Epoch [158/200], Loss: 0.5887\n",
            "Epoch [159/200], Loss: 0.5403\n",
            "Epoch [160/200], Loss: 1.5549\n",
            "Epoch [161/200], Loss: 0.8533\n",
            "Epoch [162/200], Loss: 0.6768\n",
            "Epoch [163/200], Loss: 0.8411\n",
            "Epoch [164/200], Loss: 0.8770\n",
            "Epoch [165/200], Loss: 0.5661\n",
            "Epoch [166/200], Loss: 0.6996\n",
            "Epoch [167/200], Loss: 0.5981\n",
            "Epoch [168/200], Loss: 0.7314\n",
            "Epoch [169/200], Loss: 0.4853\n",
            "Epoch [170/200], Loss: 0.7646\n",
            "Epoch [171/200], Loss: 0.5456\n",
            "Epoch [172/200], Loss: 0.6860\n",
            "Epoch [173/200], Loss: 0.7345\n",
            "Epoch [174/200], Loss: 0.4696\n",
            "Epoch [175/200], Loss: 0.6291\n",
            "Epoch [176/200], Loss: 0.6637\n",
            "Epoch [177/200], Loss: 0.7158\n",
            "Epoch [178/200], Loss: 0.8178\n",
            "Epoch [179/200], Loss: 0.6679\n",
            "Epoch [180/200], Loss: 0.8126\n",
            "Epoch [181/200], Loss: 0.9496\n",
            "Epoch [182/200], Loss: 0.6279\n",
            "Epoch [183/200], Loss: 0.5487\n",
            "Epoch [184/200], Loss: 0.5966\n",
            "Epoch [185/200], Loss: 0.5008\n",
            "Epoch [186/200], Loss: 0.8640\n",
            "Epoch [187/200], Loss: 0.8101\n",
            "Epoch [188/200], Loss: 0.8133\n",
            "Epoch [189/200], Loss: 0.5512\n",
            "Epoch [190/200], Loss: 0.7115\n",
            "Epoch [191/200], Loss: 0.8333\n",
            "Epoch [192/200], Loss: 0.7148\n",
            "Epoch [193/200], Loss: 0.7084\n",
            "Epoch [194/200], Loss: 0.5690\n",
            "Epoch [195/200], Loss: 0.7852\n",
            "Epoch [196/200], Loss: 0.9274\n",
            "Epoch [197/200], Loss: 0.9037\n",
            "Epoch [198/200], Loss: 0.8741\n",
            "Epoch [199/200], Loss: 0.5026\n",
            "Epoch [200/200], Loss: 0.6626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ορισμός της αρχιτεκτονικής του MLP\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim)  # Πρώτο επίπεδο\n",
        "        self.relu = nn.ReLU()  # Συνάρτηση ενεργοποίησης\n",
        "        self.layer2 = nn.Linear(hidden_dim, output_dim)  # Δεύτερο επίπεδο\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)  # Εφαρμογή πρώτου επιπέδου\n",
        "        x = self.relu(x)    # Εφαρμογή ReLU\n",
        "        x = self.layer2(x)  # Εφαρμογή δεύτερου επιπέδου\n",
        "        return x\n",
        "\n",
        "# Παράμετροι του μοντέλου\n",
        "input_dim = num_components  # Ο αριθμός των features μετά την SVD/encoding\n",
        "hidden_dim = 100  # Μέγεθος κρυφού επιπέδου\n",
        "output_dim = 2  # Κλάσεις για δυαδική ταξινόμηση\n",
        "\n",
        "# Δημιουργία μοντέλου\n",
        "model = MLP(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Ορισμός συσκευής (CPU ή CUDA GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Μεταφορά του μοντέλου στη συσκευή\n",
        "model = model.to(device)\n",
        "\n",
        "# Ορισμός της συνάρτησης απώλειας και του optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Συνάρτηση απώλειας\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Ενεργοποίηση του autoencoder σε λειτουργία αξιολόγησης\n",
        "model_auto.eval()\n",
        "\n",
        "# Κωδικοποίηση δεδομένων με το autoencoder\n",
        "with torch.no_grad():\n",
        "    encoded_data = model_auto.encode(X_train_tensor.to(device))\n",
        "\n",
        "# Μετατροπή των κωδικοποιημένων δεδομένων σε tensor\n",
        "encoded_data_tensor = torch.tensor(encoded_data, dtype=torch.float32)\n",
        "\n",
        "# Εκπαίδευση του μοντέλου\n",
        "num_epochs = 10000  # Αριθμός εποχών\n",
        "threshold_for_early_stop = 0.0000001  # Κατώφλι για early stopping\n",
        "patience = 100  # Πόσες φορές περιμένουμε πριν τη διακοπή\n",
        "trigger_times = 0  # Μετρητής για early stopping\n",
        "\n",
        "best_loss = float('inf')  # Καλύτερo loss\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Εκπαίδευση με τα κωδικοποιημένα δεδομένα και τις ετικέτες\n",
        "    inputs = encoded_data_tensor.to(device)\n",
        "    labels = y_train_tensor.to(device)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Έλεγχος για early stopping\n",
        "    current_loss = loss.item()\n",
        "    if best_loss - current_loss > threshold_for_early_stop:\n",
        "        best_loss = current_loss\n",
        "        trigger_times = 0  # Επαναφορά μετρητή\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:  # Έλεγχος υπομονής\n",
        "            print(f\"Early stopping! Epoch: {epoch}, Best Loss: {best_loss}\")\n",
        "            break\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, current_loss))\n"
      ],
      "metadata": {
        "id": "wOqOMMjpXd4q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d51637f-bdf3-4355-c2fc-05b89cd63d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-ffa6cabc2d2c>:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_data_tensor = torch.tensor(encoded_data, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10000], Loss: 0.6627\n",
            "Epoch [10/10000], Loss: 0.4354\n",
            "Epoch [15/10000], Loss: 0.3604\n",
            "Epoch [20/10000], Loss: 0.3265\n",
            "Epoch [25/10000], Loss: 0.2960\n",
            "Epoch [30/10000], Loss: 0.2660\n",
            "Epoch [35/10000], Loss: 0.2503\n",
            "Epoch [40/10000], Loss: 0.2392\n",
            "Epoch [45/10000], Loss: 0.2270\n",
            "Epoch [50/10000], Loss: 0.2159\n",
            "Epoch [55/10000], Loss: 0.2062\n",
            "Epoch [60/10000], Loss: 0.1980\n",
            "Epoch [65/10000], Loss: 0.1910\n",
            "Epoch [70/10000], Loss: 0.1843\n",
            "Epoch [75/10000], Loss: 0.1781\n",
            "Epoch [80/10000], Loss: 0.1725\n",
            "Epoch [85/10000], Loss: 0.1672\n",
            "Epoch [90/10000], Loss: 0.1623\n",
            "Epoch [95/10000], Loss: 0.1577\n",
            "Epoch [100/10000], Loss: 0.1533\n",
            "Epoch [105/10000], Loss: 0.1491\n",
            "Epoch [110/10000], Loss: 0.1453\n",
            "Epoch [115/10000], Loss: 0.1416\n",
            "Epoch [120/10000], Loss: 0.1381\n",
            "Epoch [125/10000], Loss: 0.1347\n",
            "Epoch [130/10000], Loss: 0.1314\n",
            "Epoch [135/10000], Loss: 0.1281\n",
            "Epoch [140/10000], Loss: 0.1252\n",
            "Epoch [145/10000], Loss: 0.1224\n",
            "Epoch [150/10000], Loss: 0.1196\n",
            "Epoch [155/10000], Loss: 0.1170\n",
            "Epoch [160/10000], Loss: 0.1144\n",
            "Epoch [165/10000], Loss: 0.1120\n",
            "Epoch [170/10000], Loss: 0.1096\n",
            "Epoch [175/10000], Loss: 0.1073\n",
            "Epoch [180/10000], Loss: 0.1052\n",
            "Epoch [185/10000], Loss: 0.1031\n",
            "Epoch [190/10000], Loss: 0.1011\n",
            "Epoch [195/10000], Loss: 0.0992\n",
            "Epoch [200/10000], Loss: 0.0974\n",
            "Epoch [205/10000], Loss: 0.0957\n",
            "Epoch [210/10000], Loss: 0.0940\n",
            "Epoch [215/10000], Loss: 0.0925\n",
            "Epoch [220/10000], Loss: 0.0910\n",
            "Epoch [225/10000], Loss: 0.0895\n",
            "Epoch [230/10000], Loss: 0.0881\n",
            "Epoch [235/10000], Loss: 0.0867\n",
            "Epoch [240/10000], Loss: 0.0854\n",
            "Epoch [245/10000], Loss: 0.0841\n",
            "Epoch [250/10000], Loss: 0.0828\n",
            "Epoch [255/10000], Loss: 0.0817\n",
            "Epoch [260/10000], Loss: 0.0810\n",
            "Epoch [265/10000], Loss: 0.0796\n",
            "Epoch [270/10000], Loss: 0.0783\n",
            "Epoch [275/10000], Loss: 0.0775\n",
            "Epoch [280/10000], Loss: 0.0762\n",
            "Epoch [285/10000], Loss: 0.0753\n",
            "Epoch [290/10000], Loss: 0.0743\n",
            "Epoch [295/10000], Loss: 0.0734\n",
            "Epoch [300/10000], Loss: 0.0724\n",
            "Epoch [305/10000], Loss: 0.0714\n",
            "Epoch [310/10000], Loss: 0.0706\n",
            "Epoch [315/10000], Loss: 0.0698\n",
            "Epoch [320/10000], Loss: 0.0688\n",
            "Epoch [325/10000], Loss: 0.0683\n",
            "Epoch [330/10000], Loss: 0.0674\n",
            "Epoch [335/10000], Loss: 0.0668\n",
            "Epoch [340/10000], Loss: 0.0659\n",
            "Epoch [345/10000], Loss: 0.0649\n",
            "Epoch [350/10000], Loss: 0.0641\n",
            "Epoch [355/10000], Loss: 0.0633\n",
            "Epoch [360/10000], Loss: 0.0626\n",
            "Epoch [365/10000], Loss: 0.0618\n",
            "Epoch [370/10000], Loss: 0.0611\n",
            "Epoch [375/10000], Loss: 0.0604\n",
            "Epoch [380/10000], Loss: 0.0598\n",
            "Epoch [385/10000], Loss: 0.0599\n",
            "Epoch [390/10000], Loss: 0.0585\n",
            "Epoch [395/10000], Loss: 0.0585\n",
            "Epoch [400/10000], Loss: 0.0573\n",
            "Epoch [405/10000], Loss: 0.0569\n",
            "Epoch [410/10000], Loss: 0.0561\n",
            "Epoch [415/10000], Loss: 0.0557\n",
            "Epoch [420/10000], Loss: 0.0550\n",
            "Epoch [425/10000], Loss: 0.0544\n",
            "Epoch [430/10000], Loss: 0.0540\n",
            "Epoch [435/10000], Loss: 0.0536\n",
            "Epoch [440/10000], Loss: 0.0528\n",
            "Epoch [445/10000], Loss: 0.0522\n",
            "Epoch [450/10000], Loss: 0.0520\n",
            "Epoch [455/10000], Loss: 0.0516\n",
            "Epoch [460/10000], Loss: 0.0507\n",
            "Epoch [465/10000], Loss: 0.0504\n",
            "Epoch [470/10000], Loss: 0.0499\n",
            "Epoch [475/10000], Loss: 0.0493\n",
            "Epoch [480/10000], Loss: 0.0488\n",
            "Epoch [485/10000], Loss: 0.0485\n",
            "Epoch [490/10000], Loss: 0.0482\n",
            "Epoch [495/10000], Loss: 0.0476\n",
            "Epoch [500/10000], Loss: 0.0471\n",
            "Epoch [505/10000], Loss: 0.0467\n",
            "Epoch [510/10000], Loss: 0.0470\n",
            "Epoch [515/10000], Loss: 0.0459\n",
            "Epoch [520/10000], Loss: 0.0455\n",
            "Epoch [525/10000], Loss: 0.0452\n",
            "Epoch [530/10000], Loss: 0.0446\n",
            "Epoch [535/10000], Loss: 0.0445\n",
            "Epoch [540/10000], Loss: 0.0449\n",
            "Epoch [545/10000], Loss: 0.0436\n",
            "Epoch [550/10000], Loss: 0.0437\n",
            "Epoch [555/10000], Loss: 0.0429\n",
            "Epoch [560/10000], Loss: 0.0428\n",
            "Epoch [565/10000], Loss: 0.0422\n",
            "Epoch [570/10000], Loss: 0.0419\n",
            "Epoch [575/10000], Loss: 0.0416\n",
            "Epoch [580/10000], Loss: 0.0415\n",
            "Epoch [585/10000], Loss: 0.0410\n",
            "Epoch [590/10000], Loss: 0.0406\n",
            "Epoch [595/10000], Loss: 0.0405\n",
            "Epoch [600/10000], Loss: 0.0408\n",
            "Epoch [605/10000], Loss: 0.0400\n",
            "Epoch [610/10000], Loss: 0.0396\n",
            "Epoch [615/10000], Loss: 0.0395\n",
            "Epoch [620/10000], Loss: 0.0389\n",
            "Epoch [625/10000], Loss: 0.0388\n",
            "Epoch [630/10000], Loss: 0.0383\n",
            "Epoch [635/10000], Loss: 0.0385\n",
            "Epoch [640/10000], Loss: 0.0379\n",
            "Epoch [645/10000], Loss: 0.0377\n",
            "Epoch [650/10000], Loss: 0.0374\n",
            "Epoch [655/10000], Loss: 0.0371\n",
            "Epoch [660/10000], Loss: 0.0369\n",
            "Epoch [665/10000], Loss: 0.0367\n",
            "Epoch [670/10000], Loss: 0.0364\n",
            "Epoch [675/10000], Loss: 0.0361\n",
            "Epoch [680/10000], Loss: 0.0359\n",
            "Epoch [685/10000], Loss: 0.0357\n",
            "Epoch [690/10000], Loss: 0.0355\n",
            "Epoch [695/10000], Loss: 0.0352\n",
            "Epoch [700/10000], Loss: 0.0380\n",
            "Epoch [705/10000], Loss: 0.0355\n",
            "Epoch [710/10000], Loss: 0.0346\n",
            "Epoch [715/10000], Loss: 0.0347\n",
            "Epoch [720/10000], Loss: 0.0343\n",
            "Epoch [725/10000], Loss: 0.0341\n",
            "Epoch [730/10000], Loss: 0.0340\n",
            "Epoch [735/10000], Loss: 0.0338\n",
            "Epoch [740/10000], Loss: 0.0335\n",
            "Epoch [745/10000], Loss: 0.0332\n",
            "Epoch [750/10000], Loss: 0.0330\n",
            "Epoch [755/10000], Loss: 0.0328\n",
            "Epoch [760/10000], Loss: 0.0325\n",
            "Epoch [765/10000], Loss: 0.0324\n",
            "Epoch [770/10000], Loss: 0.0322\n",
            "Epoch [775/10000], Loss: 0.0320\n",
            "Epoch [780/10000], Loss: 0.0318\n",
            "Epoch [785/10000], Loss: 0.0317\n",
            "Epoch [790/10000], Loss: 0.0316\n",
            "Epoch [795/10000], Loss: 0.0316\n",
            "Epoch [800/10000], Loss: 0.0313\n",
            "Epoch [805/10000], Loss: 0.0310\n",
            "Epoch [810/10000], Loss: 0.0309\n",
            "Epoch [815/10000], Loss: 0.0307\n",
            "Epoch [820/10000], Loss: 0.0305\n",
            "Epoch [825/10000], Loss: 0.0304\n",
            "Epoch [830/10000], Loss: 0.0305\n",
            "Epoch [835/10000], Loss: 0.0302\n",
            "Epoch [840/10000], Loss: 0.0301\n",
            "Epoch [845/10000], Loss: 0.0300\n",
            "Epoch [850/10000], Loss: 0.0299\n",
            "Epoch [855/10000], Loss: 0.0307\n",
            "Epoch [860/10000], Loss: 0.0294\n",
            "Epoch [865/10000], Loss: 0.0292\n",
            "Epoch [870/10000], Loss: 0.0298\n",
            "Epoch [875/10000], Loss: 0.0292\n",
            "Epoch [880/10000], Loss: 0.0290\n",
            "Epoch [885/10000], Loss: 0.0293\n",
            "Epoch [890/10000], Loss: 0.0285\n",
            "Epoch [895/10000], Loss: 0.0290\n",
            "Epoch [900/10000], Loss: 0.0285\n",
            "Epoch [905/10000], Loss: 0.0282\n",
            "Epoch [910/10000], Loss: 0.0287\n",
            "Epoch [915/10000], Loss: 0.0279\n",
            "Epoch [920/10000], Loss: 0.0280\n",
            "Epoch [925/10000], Loss: 0.0278\n",
            "Epoch [930/10000], Loss: 0.0276\n",
            "Epoch [935/10000], Loss: 0.0275\n",
            "Epoch [940/10000], Loss: 0.0274\n",
            "Epoch [945/10000], Loss: 0.0272\n",
            "Epoch [950/10000], Loss: 0.0271\n",
            "Epoch [955/10000], Loss: 0.0269\n",
            "Epoch [960/10000], Loss: 0.0268\n",
            "Epoch [965/10000], Loss: 0.0269\n",
            "Epoch [970/10000], Loss: 0.0271\n",
            "Epoch [975/10000], Loss: 0.0267\n",
            "Epoch [980/10000], Loss: 0.0264\n",
            "Epoch [985/10000], Loss: 0.0264\n",
            "Epoch [990/10000], Loss: 0.0266\n",
            "Epoch [995/10000], Loss: 0.0263\n",
            "Epoch [1000/10000], Loss: 0.0260\n",
            "Epoch [1005/10000], Loss: 0.0260\n",
            "Epoch [1010/10000], Loss: 0.0261\n",
            "Epoch [1015/10000], Loss: 0.0257\n",
            "Epoch [1020/10000], Loss: 0.0256\n",
            "Epoch [1025/10000], Loss: 0.0258\n",
            "Epoch [1030/10000], Loss: 0.0255\n",
            "Epoch [1035/10000], Loss: 0.0253\n",
            "Epoch [1040/10000], Loss: 0.0254\n",
            "Epoch [1045/10000], Loss: 0.0253\n",
            "Epoch [1050/10000], Loss: 0.0250\n",
            "Epoch [1055/10000], Loss: 0.0250\n",
            "Epoch [1060/10000], Loss: 0.0251\n",
            "Epoch [1065/10000], Loss: 0.0249\n",
            "Epoch [1070/10000], Loss: 0.0246\n",
            "Epoch [1075/10000], Loss: 0.0248\n",
            "Epoch [1080/10000], Loss: 0.0247\n",
            "Epoch [1085/10000], Loss: 0.0243\n",
            "Epoch [1090/10000], Loss: 0.0243\n",
            "Epoch [1095/10000], Loss: 0.0247\n",
            "Epoch [1100/10000], Loss: 0.0241\n",
            "Epoch [1105/10000], Loss: 0.0240\n",
            "Epoch [1110/10000], Loss: 0.0242\n",
            "Epoch [1115/10000], Loss: 0.0240\n",
            "Epoch [1120/10000], Loss: 0.0238\n",
            "Epoch [1125/10000], Loss: 0.0241\n",
            "Epoch [1130/10000], Loss: 0.0237\n",
            "Epoch [1135/10000], Loss: 0.0235\n",
            "Epoch [1140/10000], Loss: 0.0237\n",
            "Epoch [1145/10000], Loss: 0.0237\n",
            "Epoch [1150/10000], Loss: 0.0234\n",
            "Epoch [1155/10000], Loss: 0.0235\n",
            "Epoch [1160/10000], Loss: 0.0233\n",
            "Epoch [1165/10000], Loss: 0.0232\n",
            "Epoch [1170/10000], Loss: 0.0232\n",
            "Epoch [1175/10000], Loss: 0.0230\n",
            "Epoch [1180/10000], Loss: 0.0230\n",
            "Epoch [1185/10000], Loss: 0.0231\n",
            "Epoch [1190/10000], Loss: 0.0228\n",
            "Epoch [1195/10000], Loss: 0.0229\n",
            "Epoch [1200/10000], Loss: 0.0228\n",
            "Epoch [1205/10000], Loss: 0.0226\n",
            "Epoch [1210/10000], Loss: 0.0227\n",
            "Epoch [1215/10000], Loss: 0.0226\n",
            "Epoch [1220/10000], Loss: 0.0224\n",
            "Epoch [1225/10000], Loss: 0.0226\n",
            "Epoch [1230/10000], Loss: 0.0223\n",
            "Epoch [1235/10000], Loss: 0.0223\n",
            "Epoch [1240/10000], Loss: 0.0223\n",
            "Epoch [1245/10000], Loss: 0.0222\n",
            "Epoch [1250/10000], Loss: 0.0221\n",
            "Epoch [1255/10000], Loss: 0.0222\n",
            "Epoch [1260/10000], Loss: 0.0219\n",
            "Epoch [1265/10000], Loss: 0.0221\n",
            "Epoch [1270/10000], Loss: 0.0219\n",
            "Epoch [1275/10000], Loss: 0.0218\n",
            "Epoch [1280/10000], Loss: 0.0219\n",
            "Epoch [1285/10000], Loss: 0.0218\n",
            "Epoch [1290/10000], Loss: 0.0216\n",
            "Epoch [1295/10000], Loss: 0.0218\n",
            "Epoch [1300/10000], Loss: 0.0215\n",
            "Epoch [1305/10000], Loss: 0.0215\n",
            "Epoch [1310/10000], Loss: 0.0216\n",
            "Epoch [1315/10000], Loss: 0.0213\n",
            "Epoch [1320/10000], Loss: 0.0213\n",
            "Epoch [1325/10000], Loss: 0.0215\n",
            "Epoch [1330/10000], Loss: 0.0211\n",
            "Epoch [1335/10000], Loss: 0.0211\n",
            "Epoch [1340/10000], Loss: 0.0213\n",
            "Epoch [1345/10000], Loss: 0.0210\n",
            "Epoch [1350/10000], Loss: 0.0210\n",
            "Epoch [1355/10000], Loss: 0.0212\n",
            "Epoch [1360/10000], Loss: 0.0209\n",
            "Epoch [1365/10000], Loss: 0.0210\n",
            "Epoch [1370/10000], Loss: 0.0209\n",
            "Epoch [1375/10000], Loss: 0.0208\n",
            "Epoch [1380/10000], Loss: 0.0208\n",
            "Epoch [1385/10000], Loss: 0.0207\n",
            "Epoch [1390/10000], Loss: 0.0206\n",
            "Epoch [1395/10000], Loss: 0.0204\n",
            "Epoch [1400/10000], Loss: 0.0205\n",
            "Epoch [1405/10000], Loss: 0.0202\n",
            "Epoch [1410/10000], Loss: 0.0203\n",
            "Epoch [1415/10000], Loss: 0.0201\n",
            "Epoch [1420/10000], Loss: 0.0202\n",
            "Epoch [1425/10000], Loss: 0.0201\n",
            "Epoch [1430/10000], Loss: 0.0200\n",
            "Epoch [1435/10000], Loss: 0.0200\n",
            "Epoch [1440/10000], Loss: 0.0199\n",
            "Epoch [1445/10000], Loss: 0.0200\n",
            "Epoch [1450/10000], Loss: 0.0200\n",
            "Epoch [1455/10000], Loss: 0.0199\n",
            "Epoch [1460/10000], Loss: 0.0198\n",
            "Epoch [1465/10000], Loss: 0.0199\n",
            "Epoch [1470/10000], Loss: 0.0199\n",
            "Epoch [1475/10000], Loss: 0.0198\n",
            "Epoch [1480/10000], Loss: 0.0197\n",
            "Epoch [1485/10000], Loss: 0.0198\n",
            "Epoch [1490/10000], Loss: 0.0197\n",
            "Epoch [1495/10000], Loss: 0.0197\n",
            "Epoch [1500/10000], Loss: 0.0197\n",
            "Epoch [1505/10000], Loss: 0.0197\n",
            "Epoch [1510/10000], Loss: 0.0195\n",
            "Epoch [1515/10000], Loss: 0.0196\n",
            "Epoch [1520/10000], Loss: 0.0196\n",
            "Epoch [1525/10000], Loss: 0.0195\n",
            "Epoch [1530/10000], Loss: 0.0194\n",
            "Epoch [1535/10000], Loss: 0.0195\n",
            "Epoch [1540/10000], Loss: 0.0194\n",
            "Epoch [1545/10000], Loss: 0.0194\n",
            "Epoch [1550/10000], Loss: 0.0193\n",
            "Epoch [1555/10000], Loss: 0.0194\n",
            "Epoch [1560/10000], Loss: 0.0192\n",
            "Epoch [1565/10000], Loss: 0.0193\n",
            "Epoch [1570/10000], Loss: 0.0192\n",
            "Epoch [1575/10000], Loss: 0.0192\n",
            "Epoch [1580/10000], Loss: 0.0192\n",
            "Epoch [1585/10000], Loss: 0.0191\n",
            "Epoch [1590/10000], Loss: 0.0190\n",
            "Epoch [1595/10000], Loss: 0.0191\n",
            "Epoch [1600/10000], Loss: 0.0189\n",
            "Epoch [1605/10000], Loss: 0.0190\n",
            "Epoch [1610/10000], Loss: 0.0189\n",
            "Epoch [1615/10000], Loss: 0.0189\n",
            "Epoch [1620/10000], Loss: 0.0189\n",
            "Epoch [1625/10000], Loss: 0.0189\n",
            "Epoch [1630/10000], Loss: 0.0188\n",
            "Epoch [1635/10000], Loss: 0.0188\n",
            "Epoch [1640/10000], Loss: 0.0187\n",
            "Epoch [1645/10000], Loss: 0.0188\n",
            "Epoch [1650/10000], Loss: 0.0187\n",
            "Epoch [1655/10000], Loss: 0.0187\n",
            "Epoch [1660/10000], Loss: 0.0186\n",
            "Epoch [1665/10000], Loss: 0.0187\n",
            "Epoch [1670/10000], Loss: 0.0185\n",
            "Epoch [1675/10000], Loss: 0.0186\n",
            "Epoch [1680/10000], Loss: 0.0186\n",
            "Epoch [1685/10000], Loss: 0.0185\n",
            "Epoch [1690/10000], Loss: 0.0185\n",
            "Epoch [1695/10000], Loss: 0.0186\n",
            "Epoch [1700/10000], Loss: 0.0184\n",
            "Epoch [1705/10000], Loss: 0.0185\n",
            "Epoch [1710/10000], Loss: 0.0184\n",
            "Epoch [1715/10000], Loss: 0.0184\n",
            "Epoch [1720/10000], Loss: 0.0183\n",
            "Epoch [1725/10000], Loss: 0.0184\n",
            "Epoch [1730/10000], Loss: 0.0183\n",
            "Epoch [1735/10000], Loss: 0.0183\n",
            "Epoch [1740/10000], Loss: 0.0182\n",
            "Epoch [1745/10000], Loss: 0.0183\n",
            "Epoch [1750/10000], Loss: 0.0182\n",
            "Epoch [1755/10000], Loss: 0.0182\n",
            "Epoch [1760/10000], Loss: 0.0182\n",
            "Epoch [1765/10000], Loss: 0.0182\n",
            "Epoch [1770/10000], Loss: 0.0181\n",
            "Epoch [1775/10000], Loss: 0.0182\n",
            "Epoch [1780/10000], Loss: 0.0181\n",
            "Epoch [1785/10000], Loss: 0.0180\n",
            "Epoch [1790/10000], Loss: 0.0181\n",
            "Epoch [1795/10000], Loss: 0.0180\n",
            "Epoch [1800/10000], Loss: 0.0181\n",
            "Epoch [1805/10000], Loss: 0.0180\n",
            "Epoch [1810/10000], Loss: 0.0179\n",
            "Epoch [1815/10000], Loss: 0.0181\n",
            "Epoch [1820/10000], Loss: 0.0178\n",
            "Epoch [1825/10000], Loss: 0.0180\n",
            "Epoch [1830/10000], Loss: 0.0179\n",
            "Epoch [1835/10000], Loss: 0.0178\n",
            "Epoch [1840/10000], Loss: 0.0179\n",
            "Epoch [1845/10000], Loss: 0.0178\n",
            "Epoch [1850/10000], Loss: 0.0178\n",
            "Epoch [1855/10000], Loss: 0.0179\n",
            "Epoch [1860/10000], Loss: 0.0177\n",
            "Epoch [1865/10000], Loss: 0.0178\n",
            "Epoch [1870/10000], Loss: 0.0177\n",
            "Epoch [1875/10000], Loss: 0.0177\n",
            "Epoch [1880/10000], Loss: 0.0177\n",
            "Epoch [1885/10000], Loss: 0.0177\n",
            "Epoch [1890/10000], Loss: 0.0176\n",
            "Epoch [1895/10000], Loss: 0.0177\n",
            "Epoch [1900/10000], Loss: 0.0176\n",
            "Epoch [1905/10000], Loss: 0.0176\n",
            "Epoch [1910/10000], Loss: 0.0176\n",
            "Epoch [1915/10000], Loss: 0.0176\n",
            "Epoch [1920/10000], Loss: 0.0175\n",
            "Epoch [1925/10000], Loss: 0.0176\n",
            "Epoch [1930/10000], Loss: 0.0175\n",
            "Epoch [1935/10000], Loss: 0.0175\n",
            "Epoch [1940/10000], Loss: 0.0175\n",
            "Epoch [1945/10000], Loss: 0.0175\n",
            "Epoch [1950/10000], Loss: 0.0174\n",
            "Epoch [1955/10000], Loss: 0.0175\n",
            "Epoch [1960/10000], Loss: 0.0174\n",
            "Epoch [1965/10000], Loss: 0.0174\n",
            "Epoch [1970/10000], Loss: 0.0174\n",
            "Epoch [1975/10000], Loss: 0.0174\n",
            "Epoch [1980/10000], Loss: 0.0173\n",
            "Epoch [1985/10000], Loss: 0.0174\n",
            "Epoch [1990/10000], Loss: 0.0173\n",
            "Epoch [1995/10000], Loss: 0.0173\n",
            "Epoch [2000/10000], Loss: 0.0173\n",
            "Epoch [2005/10000], Loss: 0.0173\n",
            "Epoch [2010/10000], Loss: 0.0172\n",
            "Epoch [2015/10000], Loss: 0.0173\n",
            "Epoch [2020/10000], Loss: 0.0172\n",
            "Epoch [2025/10000], Loss: 0.0173\n",
            "Epoch [2030/10000], Loss: 0.0172\n",
            "Epoch [2035/10000], Loss: 0.0172\n",
            "Epoch [2040/10000], Loss: 0.0172\n",
            "Epoch [2045/10000], Loss: 0.0172\n",
            "Epoch [2050/10000], Loss: 0.0171\n",
            "Epoch [2055/10000], Loss: 0.0172\n",
            "Epoch [2060/10000], Loss: 0.0172\n",
            "Epoch [2065/10000], Loss: 0.0172\n",
            "Epoch [2070/10000], Loss: 0.0171\n",
            "Epoch [2075/10000], Loss: 0.0173\n",
            "Epoch [2080/10000], Loss: 0.0170\n",
            "Epoch [2085/10000], Loss: 0.0172\n",
            "Epoch [2090/10000], Loss: 0.0171\n",
            "Epoch [2095/10000], Loss: 0.0171\n",
            "Epoch [2100/10000], Loss: 0.0171\n",
            "Epoch [2105/10000], Loss: 0.0171\n",
            "Epoch [2110/10000], Loss: 0.0170\n",
            "Epoch [2115/10000], Loss: 0.0171\n",
            "Epoch [2120/10000], Loss: 0.0170\n",
            "Epoch [2125/10000], Loss: 0.0171\n",
            "Epoch [2130/10000], Loss: 0.0170\n",
            "Epoch [2135/10000], Loss: 0.0170\n",
            "Epoch [2140/10000], Loss: 0.0169\n",
            "Epoch [2145/10000], Loss: 0.0170\n",
            "Epoch [2150/10000], Loss: 0.0169\n",
            "Epoch [2155/10000], Loss: 0.0170\n",
            "Epoch [2160/10000], Loss: 0.0169\n",
            "Epoch [2165/10000], Loss: 0.0170\n",
            "Epoch [2170/10000], Loss: 0.0169\n",
            "Epoch [2175/10000], Loss: 0.0169\n",
            "Epoch [2180/10000], Loss: 0.0169\n",
            "Epoch [2185/10000], Loss: 0.0169\n",
            "Epoch [2190/10000], Loss: 0.0168\n",
            "Epoch [2195/10000], Loss: 0.0169\n",
            "Epoch [2200/10000], Loss: 0.0168\n",
            "Epoch [2205/10000], Loss: 0.0169\n",
            "Epoch [2210/10000], Loss: 0.0168\n",
            "Epoch [2215/10000], Loss: 0.0168\n",
            "Epoch [2220/10000], Loss: 0.0168\n",
            "Epoch [2225/10000], Loss: 0.0168\n",
            "Epoch [2230/10000], Loss: 0.0167\n",
            "Epoch [2235/10000], Loss: 0.0168\n",
            "Epoch [2240/10000], Loss: 0.0167\n",
            "Epoch [2245/10000], Loss: 0.0168\n",
            "Epoch [2250/10000], Loss: 0.0167\n",
            "Epoch [2255/10000], Loss: 0.0167\n",
            "Epoch [2260/10000], Loss: 0.0167\n",
            "Epoch [2265/10000], Loss: 0.0168\n",
            "Epoch [2270/10000], Loss: 0.0166\n",
            "Epoch [2275/10000], Loss: 0.0168\n",
            "Epoch [2280/10000], Loss: 0.0166\n",
            "Epoch [2285/10000], Loss: 0.0167\n",
            "Epoch [2290/10000], Loss: 0.0167\n",
            "Epoch [2295/10000], Loss: 0.0166\n",
            "Epoch [2300/10000], Loss: 0.0166\n",
            "Epoch [2305/10000], Loss: 0.0167\n",
            "Epoch [2310/10000], Loss: 0.0166\n",
            "Epoch [2315/10000], Loss: 0.0167\n",
            "Epoch [2320/10000], Loss: 0.0166\n",
            "Epoch [2325/10000], Loss: 0.0167\n",
            "Epoch [2330/10000], Loss: 0.0166\n",
            "Epoch [2335/10000], Loss: 0.0166\n",
            "Epoch [2340/10000], Loss: 0.0166\n",
            "Epoch [2345/10000], Loss: 0.0166\n",
            "Epoch [2350/10000], Loss: 0.0166\n",
            "Epoch [2355/10000], Loss: 0.0166\n",
            "Epoch [2360/10000], Loss: 0.0165\n",
            "Epoch [2365/10000], Loss: 0.0166\n",
            "Epoch [2370/10000], Loss: 0.0165\n",
            "Epoch [2375/10000], Loss: 0.0166\n",
            "Epoch [2380/10000], Loss: 0.0165\n",
            "Epoch [2385/10000], Loss: 0.0165\n",
            "Epoch [2390/10000], Loss: 0.0165\n",
            "Epoch [2395/10000], Loss: 0.0165\n",
            "Epoch [2400/10000], Loss: 0.0164\n",
            "Epoch [2405/10000], Loss: 0.0165\n",
            "Epoch [2410/10000], Loss: 0.0165\n",
            "Epoch [2415/10000], Loss: 0.0165\n",
            "Epoch [2420/10000], Loss: 0.0164\n",
            "Epoch [2425/10000], Loss: 0.0165\n",
            "Epoch [2430/10000], Loss: 0.0164\n",
            "Epoch [2435/10000], Loss: 0.0165\n",
            "Epoch [2440/10000], Loss: 0.0164\n",
            "Epoch [2445/10000], Loss: 0.0164\n",
            "Epoch [2450/10000], Loss: 0.0164\n",
            "Epoch [2455/10000], Loss: 0.0164\n",
            "Epoch [2460/10000], Loss: 0.0164\n",
            "Epoch [2465/10000], Loss: 0.0164\n",
            "Epoch [2470/10000], Loss: 0.0164\n",
            "Epoch [2475/10000], Loss: 0.0164\n",
            "Epoch [2480/10000], Loss: 0.0163\n",
            "Epoch [2485/10000], Loss: 0.0164\n",
            "Epoch [2490/10000], Loss: 0.0163\n",
            "Epoch [2495/10000], Loss: 0.0164\n",
            "Epoch [2500/10000], Loss: 0.0163\n",
            "Epoch [2505/10000], Loss: 0.0164\n",
            "Epoch [2510/10000], Loss: 0.0163\n",
            "Epoch [2515/10000], Loss: 0.0163\n",
            "Epoch [2520/10000], Loss: 0.0163\n",
            "Epoch [2525/10000], Loss: 0.0164\n",
            "Epoch [2530/10000], Loss: 0.0163\n",
            "Epoch [2535/10000], Loss: 0.0163\n",
            "Epoch [2540/10000], Loss: 0.0163\n",
            "Epoch [2545/10000], Loss: 0.0163\n",
            "Epoch [2550/10000], Loss: 0.0163\n",
            "Epoch [2555/10000], Loss: 0.0163\n",
            "Epoch [2560/10000], Loss: 0.0162\n",
            "Epoch [2565/10000], Loss: 0.0163\n",
            "Epoch [2570/10000], Loss: 0.0162\n",
            "Epoch [2575/10000], Loss: 0.0163\n",
            "Epoch [2580/10000], Loss: 0.0162\n",
            "Epoch [2585/10000], Loss: 0.0163\n",
            "Epoch [2590/10000], Loss: 0.0162\n",
            "Epoch [2595/10000], Loss: 0.0163\n",
            "Epoch [2600/10000], Loss: 0.0162\n",
            "Epoch [2605/10000], Loss: 0.0163\n",
            "Epoch [2610/10000], Loss: 0.0162\n",
            "Epoch [2615/10000], Loss: 0.0162\n",
            "Epoch [2620/10000], Loss: 0.0162\n",
            "Epoch [2625/10000], Loss: 0.0162\n",
            "Epoch [2630/10000], Loss: 0.0162\n",
            "Epoch [2635/10000], Loss: 0.0162\n",
            "Epoch [2640/10000], Loss: 0.0161\n",
            "Epoch [2645/10000], Loss: 0.0162\n",
            "Epoch [2650/10000], Loss: 0.0162\n",
            "Epoch [2655/10000], Loss: 0.0162\n",
            "Epoch [2660/10000], Loss: 0.0161\n",
            "Epoch [2665/10000], Loss: 0.0162\n",
            "Epoch [2670/10000], Loss: 0.0161\n",
            "Epoch [2675/10000], Loss: 0.0162\n",
            "Epoch [2680/10000], Loss: 0.0161\n",
            "Epoch [2685/10000], Loss: 0.0161\n",
            "Epoch [2690/10000], Loss: 0.0161\n",
            "Epoch [2695/10000], Loss: 0.0161\n",
            "Epoch [2700/10000], Loss: 0.0161\n",
            "Epoch [2705/10000], Loss: 0.0162\n",
            "Epoch [2710/10000], Loss: 0.0161\n",
            "Epoch [2715/10000], Loss: 0.0162\n",
            "Epoch [2720/10000], Loss: 0.0161\n",
            "Epoch [2725/10000], Loss: 0.0161\n",
            "Epoch [2730/10000], Loss: 0.0161\n",
            "Epoch [2735/10000], Loss: 0.0161\n",
            "Epoch [2740/10000], Loss: 0.0161\n",
            "Epoch [2745/10000], Loss: 0.0161\n",
            "Epoch [2750/10000], Loss: 0.0160\n",
            "Epoch [2755/10000], Loss: 0.0161\n",
            "Epoch [2760/10000], Loss: 0.0160\n",
            "Epoch [2765/10000], Loss: 0.0161\n",
            "Epoch [2770/10000], Loss: 0.0160\n",
            "Epoch [2775/10000], Loss: 0.0161\n",
            "Epoch [2780/10000], Loss: 0.0160\n",
            "Epoch [2785/10000], Loss: 0.0161\n",
            "Epoch [2790/10000], Loss: 0.0160\n",
            "Epoch [2795/10000], Loss: 0.0161\n",
            "Epoch [2800/10000], Loss: 0.0160\n",
            "Epoch [2805/10000], Loss: 0.0161\n",
            "Epoch [2810/10000], Loss: 0.0160\n",
            "Epoch [2815/10000], Loss: 0.0161\n",
            "Epoch [2820/10000], Loss: 0.0160\n",
            "Epoch [2825/10000], Loss: 0.0161\n",
            "Epoch [2830/10000], Loss: 0.0160\n",
            "Epoch [2835/10000], Loss: 0.0161\n",
            "Epoch [2840/10000], Loss: 0.0160\n",
            "Epoch [2845/10000], Loss: 0.0160\n",
            "Epoch [2850/10000], Loss: 0.0160\n",
            "Epoch [2855/10000], Loss: 0.0160\n",
            "Epoch [2860/10000], Loss: 0.0160\n",
            "Epoch [2865/10000], Loss: 0.0160\n",
            "Epoch [2870/10000], Loss: 0.0159\n",
            "Epoch [2875/10000], Loss: 0.0160\n",
            "Epoch [2880/10000], Loss: 0.0159\n",
            "Epoch [2885/10000], Loss: 0.0160\n",
            "Epoch [2890/10000], Loss: 0.0159\n",
            "Epoch [2895/10000], Loss: 0.0160\n",
            "Epoch [2900/10000], Loss: 0.0159\n",
            "Epoch [2905/10000], Loss: 0.0160\n",
            "Epoch [2910/10000], Loss: 0.0159\n",
            "Epoch [2915/10000], Loss: 0.0160\n",
            "Epoch [2920/10000], Loss: 0.0159\n",
            "Epoch [2925/10000], Loss: 0.0160\n",
            "Epoch [2930/10000], Loss: 0.0159\n",
            "Epoch [2935/10000], Loss: 0.0160\n",
            "Epoch [2940/10000], Loss: 0.0159\n",
            "Epoch [2945/10000], Loss: 0.0159\n",
            "Epoch [2950/10000], Loss: 0.0159\n",
            "Epoch [2955/10000], Loss: 0.0160\n",
            "Epoch [2960/10000], Loss: 0.0159\n",
            "Epoch [2965/10000], Loss: 0.0159\n",
            "Epoch [2970/10000], Loss: 0.0159\n",
            "Epoch [2975/10000], Loss: 0.0159\n",
            "Epoch [2980/10000], Loss: 0.0159\n",
            "Epoch [2985/10000], Loss: 0.0159\n",
            "Epoch [2990/10000], Loss: 0.0158\n",
            "Epoch [2995/10000], Loss: 0.0159\n",
            "Epoch [3000/10000], Loss: 0.0158\n",
            "Epoch [3005/10000], Loss: 0.0159\n",
            "Epoch [3010/10000], Loss: 0.0159\n",
            "Epoch [3015/10000], Loss: 0.0159\n",
            "Epoch [3020/10000], Loss: 0.0158\n",
            "Epoch [3025/10000], Loss: 0.0159\n",
            "Epoch [3030/10000], Loss: 0.0158\n",
            "Epoch [3035/10000], Loss: 0.0159\n",
            "Epoch [3040/10000], Loss: 0.0158\n",
            "Epoch [3045/10000], Loss: 0.0159\n",
            "Epoch [3050/10000], Loss: 0.0158\n",
            "Epoch [3055/10000], Loss: 0.0159\n",
            "Epoch [3060/10000], Loss: 0.0158\n",
            "Epoch [3065/10000], Loss: 0.0159\n",
            "Epoch [3070/10000], Loss: 0.0158\n",
            "Epoch [3075/10000], Loss: 0.0159\n",
            "Epoch [3080/10000], Loss: 0.0158\n",
            "Epoch [3085/10000], Loss: 0.0158\n",
            "Epoch [3090/10000], Loss: 0.0158\n",
            "Epoch [3095/10000], Loss: 0.0158\n",
            "Epoch [3100/10000], Loss: 0.0158\n",
            "Epoch [3105/10000], Loss: 0.0158\n",
            "Epoch [3110/10000], Loss: 0.0158\n",
            "Epoch [3115/10000], Loss: 0.0158\n",
            "Epoch [3120/10000], Loss: 0.0158\n",
            "Epoch [3125/10000], Loss: 0.0158\n",
            "Epoch [3130/10000], Loss: 0.0158\n",
            "Epoch [3135/10000], Loss: 0.0158\n",
            "Epoch [3140/10000], Loss: 0.0157\n",
            "Epoch [3145/10000], Loss: 0.0158\n",
            "Epoch [3150/10000], Loss: 0.0158\n",
            "Epoch [3155/10000], Loss: 0.0158\n",
            "Epoch [3160/10000], Loss: 0.0158\n",
            "Epoch [3165/10000], Loss: 0.0158\n",
            "Epoch [3170/10000], Loss: 0.0157\n",
            "Epoch [3175/10000], Loss: 0.0158\n",
            "Epoch [3180/10000], Loss: 0.0157\n",
            "Epoch [3185/10000], Loss: 0.0158\n",
            "Epoch [3190/10000], Loss: 0.0157\n",
            "Epoch [3195/10000], Loss: 0.0158\n",
            "Epoch [3200/10000], Loss: 0.0157\n",
            "Epoch [3205/10000], Loss: 0.0158\n",
            "Epoch [3210/10000], Loss: 0.0157\n",
            "Epoch [3215/10000], Loss: 0.0158\n",
            "Epoch [3220/10000], Loss: 0.0157\n",
            "Epoch [3225/10000], Loss: 0.0158\n",
            "Epoch [3230/10000], Loss: 0.0157\n",
            "Epoch [3235/10000], Loss: 0.0158\n",
            "Epoch [3240/10000], Loss: 0.0157\n",
            "Epoch [3245/10000], Loss: 0.0158\n",
            "Epoch [3250/10000], Loss: 0.0157\n",
            "Epoch [3255/10000], Loss: 0.0157\n",
            "Epoch [3260/10000], Loss: 0.0157\n",
            "Epoch [3265/10000], Loss: 0.0157\n",
            "Epoch [3270/10000], Loss: 0.0157\n",
            "Epoch [3275/10000], Loss: 0.0157\n",
            "Epoch [3280/10000], Loss: 0.0157\n",
            "Epoch [3285/10000], Loss: 0.0157\n",
            "Epoch [3290/10000], Loss: 0.0157\n",
            "Epoch [3295/10000], Loss: 0.0157\n",
            "Epoch [3300/10000], Loss: 0.0157\n",
            "Epoch [3305/10000], Loss: 0.0157\n",
            "Epoch [3310/10000], Loss: 0.0157\n",
            "Epoch [3315/10000], Loss: 0.0157\n",
            "Epoch [3320/10000], Loss: 0.0157\n",
            "Epoch [3325/10000], Loss: 0.0157\n",
            "Epoch [3330/10000], Loss: 0.0157\n",
            "Epoch [3335/10000], Loss: 0.0157\n",
            "Epoch [3340/10000], Loss: 0.0157\n",
            "Epoch [3345/10000], Loss: 0.0157\n",
            "Epoch [3350/10000], Loss: 0.0156\n",
            "Epoch [3355/10000], Loss: 0.0157\n",
            "Epoch [3360/10000], Loss: 0.0157\n",
            "Epoch [3365/10000], Loss: 0.0157\n",
            "Epoch [3370/10000], Loss: 0.0157\n",
            "Epoch [3375/10000], Loss: 0.0157\n",
            "Epoch [3380/10000], Loss: 0.0156\n",
            "Epoch [3385/10000], Loss: 0.0157\n",
            "Epoch [3390/10000], Loss: 0.0156\n",
            "Epoch [3395/10000], Loss: 0.0157\n",
            "Epoch [3400/10000], Loss: 0.0156\n",
            "Epoch [3405/10000], Loss: 0.0157\n",
            "Epoch [3410/10000], Loss: 0.0156\n",
            "Epoch [3415/10000], Loss: 0.0157\n",
            "Epoch [3420/10000], Loss: 0.0156\n",
            "Epoch [3425/10000], Loss: 0.0157\n",
            "Epoch [3430/10000], Loss: 0.0156\n",
            "Epoch [3435/10000], Loss: 0.0157\n",
            "Epoch [3440/10000], Loss: 0.0156\n",
            "Epoch [3445/10000], Loss: 0.0157\n",
            "Epoch [3450/10000], Loss: 0.0156\n",
            "Epoch [3455/10000], Loss: 0.0157\n",
            "Epoch [3460/10000], Loss: 0.0156\n",
            "Epoch [3465/10000], Loss: 0.0157\n",
            "Epoch [3470/10000], Loss: 0.0156\n",
            "Epoch [3475/10000], Loss: 0.0157\n",
            "Epoch [3480/10000], Loss: 0.0156\n",
            "Epoch [3485/10000], Loss: 0.0156\n",
            "Epoch [3490/10000], Loss: 0.0156\n",
            "Epoch [3495/10000], Loss: 0.0157\n",
            "Epoch [3500/10000], Loss: 0.0156\n",
            "Epoch [3505/10000], Loss: 0.0156\n",
            "Epoch [3510/10000], Loss: 0.0156\n",
            "Epoch [3515/10000], Loss: 0.0156\n",
            "Epoch [3520/10000], Loss: 0.0156\n",
            "Epoch [3525/10000], Loss: 0.0157\n",
            "Epoch [3530/10000], Loss: 0.0156\n",
            "Epoch [3535/10000], Loss: 0.0156\n",
            "Epoch [3540/10000], Loss: 0.0156\n",
            "Epoch [3545/10000], Loss: 0.0156\n",
            "Epoch [3550/10000], Loss: 0.0156\n",
            "Epoch [3555/10000], Loss: 0.0156\n",
            "Epoch [3560/10000], Loss: 0.0156\n",
            "Epoch [3565/10000], Loss: 0.0156\n",
            "Epoch [3570/10000], Loss: 0.0156\n",
            "Epoch [3575/10000], Loss: 0.0156\n",
            "Epoch [3580/10000], Loss: 0.0156\n",
            "Epoch [3585/10000], Loss: 0.0156\n",
            "Epoch [3590/10000], Loss: 0.0155\n",
            "Epoch [3595/10000], Loss: 0.0156\n",
            "Epoch [3600/10000], Loss: 0.0156\n",
            "Epoch [3605/10000], Loss: 0.0156\n",
            "Epoch [3610/10000], Loss: 0.0155\n",
            "Epoch [3615/10000], Loss: 0.0156\n",
            "Epoch [3620/10000], Loss: 0.0155\n",
            "Epoch [3625/10000], Loss: 0.0156\n",
            "Epoch [3630/10000], Loss: 0.0155\n",
            "Epoch [3635/10000], Loss: 0.0156\n",
            "Epoch [3640/10000], Loss: 0.0155\n",
            "Epoch [3645/10000], Loss: 0.0156\n",
            "Epoch [3650/10000], Loss: 0.0155\n",
            "Epoch [3655/10000], Loss: 0.0156\n",
            "Epoch [3660/10000], Loss: 0.0155\n",
            "Epoch [3665/10000], Loss: 0.0156\n",
            "Epoch [3670/10000], Loss: 0.0155\n",
            "Epoch [3675/10000], Loss: 0.0156\n",
            "Epoch [3680/10000], Loss: 0.0155\n",
            "Epoch [3685/10000], Loss: 0.0156\n",
            "Epoch [3690/10000], Loss: 0.0155\n",
            "Epoch [3695/10000], Loss: 0.0156\n",
            "Epoch [3700/10000], Loss: 0.0155\n",
            "Epoch [3705/10000], Loss: 0.0156\n",
            "Epoch [3710/10000], Loss: 0.0155\n",
            "Epoch [3715/10000], Loss: 0.0156\n",
            "Epoch [3720/10000], Loss: 0.0155\n",
            "Epoch [3725/10000], Loss: 0.0155\n",
            "Epoch [3730/10000], Loss: 0.0155\n",
            "Epoch [3735/10000], Loss: 0.0155\n",
            "Epoch [3740/10000], Loss: 0.0155\n",
            "Epoch [3745/10000], Loss: 0.0155\n",
            "Epoch [3750/10000], Loss: 0.0155\n",
            "Epoch [3755/10000], Loss: 0.0156\n",
            "Epoch [3760/10000], Loss: 0.0155\n",
            "Epoch [3765/10000], Loss: 0.0155\n",
            "Epoch [3770/10000], Loss: 0.0155\n",
            "Epoch [3775/10000], Loss: 0.0155\n",
            "Epoch [3780/10000], Loss: 0.0155\n",
            "Epoch [3785/10000], Loss: 0.0156\n",
            "Epoch [3790/10000], Loss: 0.0155\n",
            "Epoch [3795/10000], Loss: 0.0155\n",
            "Epoch [3800/10000], Loss: 0.0155\n",
            "Epoch [3805/10000], Loss: 0.0155\n",
            "Epoch [3810/10000], Loss: 0.0155\n",
            "Epoch [3815/10000], Loss: 0.0155\n",
            "Epoch [3820/10000], Loss: 0.0154\n",
            "Epoch [3825/10000], Loss: 0.0156\n",
            "Epoch [3830/10000], Loss: 0.0155\n",
            "Epoch [3835/10000], Loss: 0.0155\n",
            "Epoch [3840/10000], Loss: 0.0155\n",
            "Epoch [3845/10000], Loss: 0.0155\n",
            "Epoch [3850/10000], Loss: 0.0155\n",
            "Epoch [3855/10000], Loss: 0.0155\n",
            "Epoch [3860/10000], Loss: 0.0155\n",
            "Epoch [3865/10000], Loss: 0.0155\n",
            "Epoch [3870/10000], Loss: 0.0155\n",
            "Epoch [3875/10000], Loss: 0.0155\n",
            "Epoch [3880/10000], Loss: 0.0155\n",
            "Epoch [3885/10000], Loss: 0.0155\n",
            "Epoch [3890/10000], Loss: 0.0154\n",
            "Epoch [3895/10000], Loss: 0.0155\n",
            "Epoch [3900/10000], Loss: 0.0154\n",
            "Epoch [3905/10000], Loss: 0.0155\n",
            "Epoch [3910/10000], Loss: 0.0155\n",
            "Epoch [3915/10000], Loss: 0.0155\n",
            "Epoch [3920/10000], Loss: 0.0155\n",
            "Epoch [3925/10000], Loss: 0.0155\n",
            "Epoch [3930/10000], Loss: 0.0154\n",
            "Epoch [3935/10000], Loss: 0.0155\n",
            "Epoch [3940/10000], Loss: 0.0154\n",
            "Epoch [3945/10000], Loss: 0.0155\n",
            "Epoch [3950/10000], Loss: 0.0154\n",
            "Epoch [3955/10000], Loss: 0.0155\n",
            "Epoch [3960/10000], Loss: 0.0154\n",
            "Epoch [3965/10000], Loss: 0.0155\n",
            "Epoch [3970/10000], Loss: 0.0154\n",
            "Epoch [3975/10000], Loss: 0.0155\n",
            "Epoch [3980/10000], Loss: 0.0154\n",
            "Epoch [3985/10000], Loss: 0.0155\n",
            "Epoch [3990/10000], Loss: 0.0154\n",
            "Epoch [3995/10000], Loss: 0.0155\n",
            "Epoch [4000/10000], Loss: 0.0154\n",
            "Epoch [4005/10000], Loss: 0.0155\n",
            "Epoch [4010/10000], Loss: 0.0154\n",
            "Epoch [4015/10000], Loss: 0.0155\n",
            "Epoch [4020/10000], Loss: 0.0154\n",
            "Epoch [4025/10000], Loss: 0.0155\n",
            "Epoch [4030/10000], Loss: 0.0154\n",
            "Epoch [4035/10000], Loss: 0.0155\n",
            "Epoch [4040/10000], Loss: 0.0154\n",
            "Epoch [4045/10000], Loss: 0.0155\n",
            "Epoch [4050/10000], Loss: 0.0154\n",
            "Epoch [4055/10000], Loss: 0.0155\n",
            "Epoch [4060/10000], Loss: 0.0154\n",
            "Epoch [4065/10000], Loss: 0.0154\n",
            "Epoch [4070/10000], Loss: 0.0154\n",
            "Epoch [4075/10000], Loss: 0.0155\n",
            "Epoch [4080/10000], Loss: 0.0154\n",
            "Epoch [4085/10000], Loss: 0.0155\n",
            "Epoch [4090/10000], Loss: 0.0154\n",
            "Epoch [4095/10000], Loss: 0.0155\n",
            "Epoch [4100/10000], Loss: 0.0154\n",
            "Epoch [4105/10000], Loss: 0.0155\n",
            "Epoch [4110/10000], Loss: 0.0154\n",
            "Epoch [4115/10000], Loss: 0.0154\n",
            "Epoch [4120/10000], Loss: 0.0154\n",
            "Epoch [4125/10000], Loss: 0.0155\n",
            "Epoch [4130/10000], Loss: 0.0154\n",
            "Epoch [4135/10000], Loss: 0.0155\n",
            "Epoch [4140/10000], Loss: 0.0154\n",
            "Epoch [4145/10000], Loss: 0.0154\n",
            "Epoch [4150/10000], Loss: 0.0154\n",
            "Epoch [4155/10000], Loss: 0.0154\n",
            "Epoch [4160/10000], Loss: 0.0154\n",
            "Epoch [4165/10000], Loss: 0.0155\n",
            "Epoch [4170/10000], Loss: 0.0154\n",
            "Epoch [4175/10000], Loss: 0.0154\n",
            "Epoch [4180/10000], Loss: 0.0154\n",
            "Epoch [4185/10000], Loss: 0.0154\n",
            "Epoch [4190/10000], Loss: 0.0154\n",
            "Epoch [4195/10000], Loss: 0.0154\n",
            "Epoch [4200/10000], Loss: 0.0154\n",
            "Epoch [4205/10000], Loss: 0.0154\n",
            "Epoch [4210/10000], Loss: 0.0154\n",
            "Epoch [4215/10000], Loss: 0.0154\n",
            "Epoch [4220/10000], Loss: 0.0154\n",
            "Epoch [4225/10000], Loss: 0.0154\n",
            "Epoch [4230/10000], Loss: 0.0154\n",
            "Epoch [4235/10000], Loss: 0.0154\n",
            "Epoch [4240/10000], Loss: 0.0154\n",
            "Epoch [4245/10000], Loss: 0.0154\n",
            "Epoch [4250/10000], Loss: 0.0154\n",
            "Epoch [4255/10000], Loss: 0.0154\n",
            "Epoch [4260/10000], Loss: 0.0154\n",
            "Epoch [4265/10000], Loss: 0.0154\n",
            "Epoch [4270/10000], Loss: 0.0154\n",
            "Epoch [4275/10000], Loss: 0.0154\n",
            "Epoch [4280/10000], Loss: 0.0154\n",
            "Epoch [4285/10000], Loss: 0.0154\n",
            "Epoch [4290/10000], Loss: 0.0154\n",
            "Epoch [4295/10000], Loss: 0.0154\n",
            "Epoch [4300/10000], Loss: 0.0154\n",
            "Epoch [4305/10000], Loss: 0.0154\n",
            "Epoch [4310/10000], Loss: 0.0153\n",
            "Epoch [4315/10000], Loss: 0.0154\n",
            "Epoch [4320/10000], Loss: 0.0153\n",
            "Epoch [4325/10000], Loss: 0.0154\n",
            "Epoch [4330/10000], Loss: 0.0153\n",
            "Epoch [4335/10000], Loss: 0.0153\n",
            "Epoch [4340/10000], Loss: 0.0153\n",
            "Epoch [4345/10000], Loss: 0.0154\n",
            "Epoch [4350/10000], Loss: 0.0153\n",
            "Epoch [4355/10000], Loss: 0.0154\n",
            "Epoch [4360/10000], Loss: 0.0153\n",
            "Epoch [4365/10000], Loss: 0.0153\n",
            "Epoch [4370/10000], Loss: 0.0153\n",
            "Epoch [4375/10000], Loss: 0.0154\n",
            "Epoch [4380/10000], Loss: 0.0153\n",
            "Epoch [4385/10000], Loss: 0.0154\n",
            "Epoch [4390/10000], Loss: 0.0153\n",
            "Epoch [4395/10000], Loss: 0.0154\n",
            "Epoch [4400/10000], Loss: 0.0153\n",
            "Epoch [4405/10000], Loss: 0.0154\n",
            "Epoch [4410/10000], Loss: 0.0153\n",
            "Epoch [4415/10000], Loss: 0.0154\n",
            "Epoch [4420/10000], Loss: 0.0153\n",
            "Epoch [4425/10000], Loss: 0.0154\n",
            "Epoch [4430/10000], Loss: 0.0153\n",
            "Epoch [4435/10000], Loss: 0.0154\n",
            "Early stopping! Epoch: 4435, Best Loss: 0.015251974575221539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**β)**"
      ],
      "metadata": {
        "id": "TNi8PdoMLI0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ορισμός της αρχιτεκτονικής του MLP_2\n",
        "class MLP_2(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
        "        super(MLP_2, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim1)\n",
        "        self.layer2 = nn.Linear(hidden_dim1, hidden_dim2)  # Νέο επίπεδο\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer3 = nn.Linear(hidden_dim2, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)  # Εφαρμογή dropout\n",
        "        x = self.layer2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "\n",
        "# Παράμετροι του μοντέλου\n",
        "input_dim = num_components  #  ο αριθμός των features μετά την SVD/encoding\n",
        "hidden_dim1 = 100\n",
        "hidden_dim2 = 50   # Νέο μέγεθος για την δεύτερη κρυφή στοιβάδα\n",
        "output_dim = 2  # 2 κλάσεις\n",
        "\n",
        "# Δημιουργία μοντέλου\n",
        "model_2 = MLP_2(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
        "\n",
        "# Ορισμός συσκευής (CPU ή CUDA GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Μεταφορά του μοντέλου στη συσκευή\n",
        "model_2 = model_2.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_2.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# Εκπαίδευση του μοντέλου\n",
        "num_epochs = 10000\n",
        "threshold_for_early_stop = 0.0000001  # Κατώφλι για early stopping\n",
        "patience = 100  # Πόσες φορές περιμένουμε πριν τη διακοπή\n",
        "trigger_times = 0  # Μετρητής για early stopping\n",
        "best_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_2(encoded_data_tensor)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Έλεγχος για early stopping\n",
        "    current_loss = loss.item()\n",
        "    if best_loss - current_loss > threshold_for_early_stop:\n",
        "        best_loss = current_loss\n",
        "        trigger_times = 0\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:\n",
        "            print(f\"Early stopping! Epoch: {epoch}, Best Loss: {best_loss}\")\n",
        "            break\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, current_loss))\n"
      ],
      "metadata": {
        "id": "oQDL2OlvMOuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd4f56f-cb6a-4139-8463-7740d3142573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10000], Loss: 0.6867\n",
            "Epoch [10/10000], Loss: 0.5708\n",
            "Epoch [15/10000], Loss: 0.4572\n",
            "Epoch [20/10000], Loss: 0.4134\n",
            "Epoch [25/10000], Loss: 0.3817\n",
            "Epoch [30/10000], Loss: 0.3559\n",
            "Epoch [35/10000], Loss: 0.3412\n",
            "Epoch [40/10000], Loss: 0.3185\n",
            "Epoch [45/10000], Loss: 0.2902\n",
            "Epoch [50/10000], Loss: 0.2671\n",
            "Epoch [55/10000], Loss: 0.2691\n",
            "Epoch [60/10000], Loss: 0.2648\n",
            "Epoch [65/10000], Loss: 0.2462\n",
            "Epoch [70/10000], Loss: 0.2397\n",
            "Epoch [75/10000], Loss: 0.2307\n",
            "Epoch [80/10000], Loss: 0.2301\n",
            "Epoch [85/10000], Loss: 0.2237\n",
            "Epoch [90/10000], Loss: 0.2229\n",
            "Epoch [95/10000], Loss: 0.2135\n",
            "Epoch [100/10000], Loss: 0.2143\n",
            "Epoch [105/10000], Loss: 0.2155\n",
            "Epoch [110/10000], Loss: 0.2024\n",
            "Epoch [115/10000], Loss: 0.2050\n",
            "Epoch [120/10000], Loss: 0.1931\n",
            "Epoch [125/10000], Loss: 0.1942\n",
            "Epoch [130/10000], Loss: 0.1982\n",
            "Epoch [135/10000], Loss: 0.1914\n",
            "Epoch [140/10000], Loss: 0.1851\n",
            "Epoch [145/10000], Loss: 0.1768\n",
            "Epoch [150/10000], Loss: 0.1755\n",
            "Epoch [155/10000], Loss: 0.1757\n",
            "Epoch [160/10000], Loss: 0.1662\n",
            "Epoch [165/10000], Loss: 0.1515\n",
            "Epoch [170/10000], Loss: 0.1601\n",
            "Epoch [175/10000], Loss: 0.1592\n",
            "Epoch [180/10000], Loss: 0.1612\n",
            "Epoch [185/10000], Loss: 0.1586\n",
            "Epoch [190/10000], Loss: 0.1646\n",
            "Epoch [195/10000], Loss: 0.1495\n",
            "Epoch [200/10000], Loss: 0.1464\n",
            "Epoch [205/10000], Loss: 0.1567\n",
            "Epoch [210/10000], Loss: 0.1336\n",
            "Epoch [215/10000], Loss: 0.1470\n",
            "Epoch [220/10000], Loss: 0.1412\n",
            "Epoch [225/10000], Loss: 0.1424\n",
            "Epoch [230/10000], Loss: 0.1408\n",
            "Epoch [235/10000], Loss: 0.1387\n",
            "Epoch [240/10000], Loss: 0.1350\n",
            "Epoch [245/10000], Loss: 0.1441\n",
            "Epoch [250/10000], Loss: 0.1224\n",
            "Epoch [255/10000], Loss: 0.1302\n",
            "Epoch [260/10000], Loss: 0.1369\n",
            "Epoch [265/10000], Loss: 0.1277\n",
            "Epoch [270/10000], Loss: 0.1267\n",
            "Epoch [275/10000], Loss: 0.1247\n",
            "Epoch [280/10000], Loss: 0.1272\n",
            "Epoch [285/10000], Loss: 0.1179\n",
            "Epoch [290/10000], Loss: 0.1220\n",
            "Epoch [295/10000], Loss: 0.1166\n",
            "Epoch [300/10000], Loss: 0.1151\n",
            "Epoch [305/10000], Loss: 0.1095\n",
            "Epoch [310/10000], Loss: 0.1239\n",
            "Epoch [315/10000], Loss: 0.1272\n",
            "Epoch [320/10000], Loss: 0.1104\n",
            "Epoch [325/10000], Loss: 0.1122\n",
            "Epoch [330/10000], Loss: 0.1142\n",
            "Epoch [335/10000], Loss: 0.1084\n",
            "Epoch [340/10000], Loss: 0.1151\n",
            "Epoch [345/10000], Loss: 0.1040\n",
            "Epoch [350/10000], Loss: 0.0998\n",
            "Epoch [355/10000], Loss: 0.1110\n",
            "Epoch [360/10000], Loss: 0.1052\n",
            "Epoch [365/10000], Loss: 0.1043\n",
            "Epoch [370/10000], Loss: 0.1054\n",
            "Epoch [375/10000], Loss: 0.1034\n",
            "Epoch [380/10000], Loss: 0.0992\n",
            "Epoch [385/10000], Loss: 0.0927\n",
            "Epoch [390/10000], Loss: 0.1086\n",
            "Epoch [395/10000], Loss: 0.0979\n",
            "Epoch [400/10000], Loss: 0.0940\n",
            "Epoch [405/10000], Loss: 0.0988\n",
            "Epoch [410/10000], Loss: 0.0916\n",
            "Epoch [415/10000], Loss: 0.0886\n",
            "Epoch [420/10000], Loss: 0.0927\n",
            "Epoch [425/10000], Loss: 0.0872\n",
            "Epoch [430/10000], Loss: 0.0893\n",
            "Epoch [435/10000], Loss: 0.0906\n",
            "Epoch [440/10000], Loss: 0.0873\n",
            "Epoch [445/10000], Loss: 0.0916\n",
            "Epoch [450/10000], Loss: 0.0815\n",
            "Epoch [455/10000], Loss: 0.0866\n",
            "Epoch [460/10000], Loss: 0.0841\n",
            "Epoch [465/10000], Loss: 0.0856\n",
            "Epoch [470/10000], Loss: 0.0871\n",
            "Epoch [475/10000], Loss: 0.0864\n",
            "Epoch [480/10000], Loss: 0.0872\n",
            "Epoch [485/10000], Loss: 0.0860\n",
            "Epoch [490/10000], Loss: 0.0813\n",
            "Epoch [495/10000], Loss: 0.0841\n",
            "Epoch [500/10000], Loss: 0.0813\n",
            "Epoch [505/10000], Loss: 0.0823\n",
            "Epoch [510/10000], Loss: 0.0738\n",
            "Epoch [515/10000], Loss: 0.0844\n",
            "Epoch [520/10000], Loss: 0.0835\n",
            "Epoch [525/10000], Loss: 0.0873\n",
            "Epoch [530/10000], Loss: 0.0810\n",
            "Epoch [535/10000], Loss: 0.0852\n",
            "Epoch [540/10000], Loss: 0.0771\n",
            "Epoch [545/10000], Loss: 0.0798\n",
            "Epoch [550/10000], Loss: 0.0835\n",
            "Epoch [555/10000], Loss: 0.0767\n",
            "Epoch [560/10000], Loss: 0.0764\n",
            "Epoch [565/10000], Loss: 0.0897\n",
            "Epoch [570/10000], Loss: 0.0826\n",
            "Epoch [575/10000], Loss: 0.0773\n",
            "Epoch [580/10000], Loss: 0.0765\n",
            "Epoch [585/10000], Loss: 0.0643\n",
            "Epoch [590/10000], Loss: 0.0749\n",
            "Epoch [595/10000], Loss: 0.0779\n",
            "Epoch [600/10000], Loss: 0.0779\n",
            "Epoch [605/10000], Loss: 0.0682\n",
            "Epoch [610/10000], Loss: 0.0729\n",
            "Epoch [615/10000], Loss: 0.0742\n",
            "Epoch [620/10000], Loss: 0.0746\n",
            "Epoch [625/10000], Loss: 0.0731\n",
            "Epoch [630/10000], Loss: 0.0774\n",
            "Epoch [635/10000], Loss: 0.0766\n",
            "Epoch [640/10000], Loss: 0.0712\n",
            "Epoch [645/10000], Loss: 0.0707\n",
            "Epoch [650/10000], Loss: 0.0751\n",
            "Epoch [655/10000], Loss: 0.0715\n",
            "Epoch [660/10000], Loss: 0.0652\n",
            "Epoch [665/10000], Loss: 0.0713\n",
            "Epoch [670/10000], Loss: 0.0743\n",
            "Epoch [675/10000], Loss: 0.0676\n",
            "Epoch [680/10000], Loss: 0.0722\n",
            "Early stopping! Epoch: 684, Best Loss: 0.06425197422504425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ορισμός της αρχιτεκτονικής του MLP_3\n",
        "class MLP_3(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
        "        super(MLP_3, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim1)\n",
        "        self.layer2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer3 = nn.Linear(hidden_dim2, output_dim)\n",
        "        # Προσθήκη ενός ακόμη κρυφού επιπέδου\n",
        "        self.layer4 = nn.Linear(hidden_dim2, hidden_dim2)\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout layer\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)  # Εφαρμογή dropout\n",
        "        x = self.layer2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer4(x)  # Προσθήκη της επιπλέον κρυφής στοιβάδας\n",
        "        x = self.relu(x)\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "\n",
        "# Ορισμός νέου μοντέλου\n",
        "model_3 = MLP_3(input_dim, hidden_dim1, hidden_dim2, output_dim).to(device)\n",
        "\n",
        "\n",
        "# Παράμετροι του μοντέλου\n",
        "input_dim = num_components  #  ο αριθμός των features μετά την SVD/encoding\n",
        "hidden_dim1 = 100\n",
        "hidden_dim2 = 50   # Νέο μέγεθος για την δεύτερη κρυφή στοιβάδα\n",
        "output_dim = 2  # 2 κλάσεις\n",
        "\n",
        "\n",
        "\n",
        "# Ορισμός συσκευής (CPU ή CUDA GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Μεταφορά του μοντέλου στη συσκευή\n",
        "model_3 = model_3.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_3.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# Εκπαίδευση του μοντέλου\n",
        "num_epochs = 10000\n",
        "threshold_for_early_stop = 0.0000001  # Κατώφλι για early stopping\n",
        "patience = 100  # Πόσες φορές περιμένουμε πριν τη διακοπή\n",
        "trigger_times = 0  # Μετρητής για early stopping\n",
        "best_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_3(encoded_data_tensor)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Έλεγχος για early stopping\n",
        "    current_loss = loss.item()\n",
        "    if best_loss - current_loss > threshold_for_early_stop:\n",
        "        best_loss = current_loss\n",
        "        trigger_times = 0\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:\n",
        "            print(f\"Early stopping! Epoch: {epoch}, Best Loss: {best_loss}\")\n",
        "            break\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, current_loss))\n"
      ],
      "metadata": {
        "id": "3CJ6g0bcS9SN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "807fcb19-9429-4465-f9c2-191209891d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10000], Loss: 0.6328\n",
            "Epoch [10/10000], Loss: 0.5037\n",
            "Epoch [15/10000], Loss: 0.4728\n",
            "Epoch [20/10000], Loss: 0.4184\n",
            "Epoch [25/10000], Loss: 0.4059\n",
            "Epoch [30/10000], Loss: 0.3785\n",
            "Epoch [35/10000], Loss: 0.3420\n",
            "Epoch [40/10000], Loss: 0.3214\n",
            "Epoch [45/10000], Loss: 0.3042\n",
            "Epoch [50/10000], Loss: 0.3133\n",
            "Epoch [55/10000], Loss: 0.2807\n",
            "Epoch [60/10000], Loss: 0.2695\n",
            "Epoch [65/10000], Loss: 0.2707\n",
            "Epoch [70/10000], Loss: 0.2646\n",
            "Epoch [75/10000], Loss: 0.2451\n",
            "Epoch [80/10000], Loss: 0.2366\n",
            "Epoch [85/10000], Loss: 0.2155\n",
            "Epoch [90/10000], Loss: 0.2184\n",
            "Epoch [95/10000], Loss: 0.2176\n",
            "Epoch [100/10000], Loss: 0.2135\n",
            "Epoch [105/10000], Loss: 0.2063\n",
            "Epoch [110/10000], Loss: 0.1869\n",
            "Epoch [115/10000], Loss: 0.1813\n",
            "Epoch [120/10000], Loss: 0.1851\n",
            "Epoch [125/10000], Loss: 0.1760\n",
            "Epoch [130/10000], Loss: 0.1714\n",
            "Epoch [135/10000], Loss: 0.1746\n",
            "Epoch [140/10000], Loss: 0.1691\n",
            "Epoch [145/10000], Loss: 0.1625\n",
            "Epoch [150/10000], Loss: 0.1533\n",
            "Epoch [155/10000], Loss: 0.1486\n",
            "Epoch [160/10000], Loss: 0.1516\n",
            "Epoch [165/10000], Loss: 0.1490\n",
            "Epoch [170/10000], Loss: 0.1478\n",
            "Epoch [175/10000], Loss: 0.1486\n",
            "Epoch [180/10000], Loss: 0.1464\n",
            "Epoch [185/10000], Loss: 0.1298\n",
            "Epoch [190/10000], Loss: 0.1436\n",
            "Epoch [195/10000], Loss: 0.1225\n",
            "Epoch [200/10000], Loss: 0.1231\n",
            "Epoch [205/10000], Loss: 0.1252\n",
            "Epoch [210/10000], Loss: 0.1167\n",
            "Epoch [215/10000], Loss: 0.1234\n",
            "Epoch [220/10000], Loss: 0.1271\n",
            "Epoch [225/10000], Loss: 0.1135\n",
            "Epoch [230/10000], Loss: 0.1219\n",
            "Epoch [235/10000], Loss: 0.1226\n",
            "Epoch [240/10000], Loss: 0.1266\n",
            "Epoch [245/10000], Loss: 0.1058\n",
            "Epoch [250/10000], Loss: 0.1160\n",
            "Epoch [255/10000], Loss: 0.1197\n",
            "Epoch [260/10000], Loss: 0.1037\n",
            "Epoch [265/10000], Loss: 0.1138\n",
            "Epoch [270/10000], Loss: 0.1049\n",
            "Epoch [275/10000], Loss: 0.1038\n",
            "Epoch [280/10000], Loss: 0.1138\n",
            "Epoch [285/10000], Loss: 0.1000\n",
            "Epoch [290/10000], Loss: 0.1031\n",
            "Epoch [295/10000], Loss: 0.1026\n",
            "Epoch [300/10000], Loss: 0.1148\n",
            "Epoch [305/10000], Loss: 0.1121\n",
            "Epoch [310/10000], Loss: 0.0929\n",
            "Epoch [315/10000], Loss: 0.1015\n",
            "Epoch [320/10000], Loss: 0.0945\n",
            "Epoch [325/10000], Loss: 0.1058\n",
            "Epoch [330/10000], Loss: 0.0976\n",
            "Epoch [335/10000], Loss: 0.1030\n",
            "Epoch [340/10000], Loss: 0.0903\n",
            "Epoch [345/10000], Loss: 0.0935\n",
            "Epoch [350/10000], Loss: 0.0847\n",
            "Epoch [355/10000], Loss: 0.0840\n",
            "Epoch [360/10000], Loss: 0.0922\n",
            "Epoch [365/10000], Loss: 0.0866\n",
            "Epoch [370/10000], Loss: 0.0870\n",
            "Epoch [375/10000], Loss: 0.0831\n",
            "Epoch [380/10000], Loss: 0.0893\n",
            "Epoch [385/10000], Loss: 0.0795\n",
            "Epoch [390/10000], Loss: 0.0887\n",
            "Epoch [395/10000], Loss: 0.0814\n",
            "Epoch [400/10000], Loss: 0.0930\n",
            "Epoch [405/10000], Loss: 0.0846\n",
            "Epoch [410/10000], Loss: 0.0731\n",
            "Epoch [415/10000], Loss: 0.0840\n",
            "Epoch [420/10000], Loss: 0.0808\n",
            "Epoch [425/10000], Loss: 0.0879\n",
            "Epoch [430/10000], Loss: 0.0776\n",
            "Epoch [435/10000], Loss: 0.0859\n",
            "Epoch [440/10000], Loss: 0.0816\n",
            "Epoch [445/10000], Loss: 0.0782\n",
            "Epoch [450/10000], Loss: 0.0703\n",
            "Epoch [455/10000], Loss: 0.0837\n",
            "Epoch [460/10000], Loss: 0.0777\n",
            "Epoch [465/10000], Loss: 0.0753\n",
            "Epoch [470/10000], Loss: 0.0787\n",
            "Epoch [475/10000], Loss: 0.0742\n",
            "Epoch [480/10000], Loss: 0.0692\n",
            "Epoch [485/10000], Loss: 0.0758\n",
            "Epoch [490/10000], Loss: 0.0752\n",
            "Epoch [495/10000], Loss: 0.0714\n",
            "Epoch [500/10000], Loss: 0.0668\n",
            "Epoch [505/10000], Loss: 0.0676\n",
            "Epoch [510/10000], Loss: 0.0653\n",
            "Epoch [515/10000], Loss: 0.0665\n",
            "Epoch [520/10000], Loss: 0.0708\n",
            "Epoch [525/10000], Loss: 0.0713\n",
            "Epoch [530/10000], Loss: 0.0655\n",
            "Epoch [535/10000], Loss: 0.0795\n",
            "Epoch [540/10000], Loss: 0.0718\n",
            "Epoch [545/10000], Loss: 0.0764\n",
            "Epoch [550/10000], Loss: 0.0853\n",
            "Epoch [555/10000], Loss: 0.0831\n",
            "Epoch [560/10000], Loss: 0.0652\n",
            "Epoch [565/10000], Loss: 0.0702\n",
            "Epoch [570/10000], Loss: 0.0696\n",
            "Epoch [575/10000], Loss: 0.0691\n",
            "Epoch [580/10000], Loss: 0.0691\n",
            "Epoch [585/10000], Loss: 0.0652\n",
            "Epoch [590/10000], Loss: 0.0619\n",
            "Epoch [595/10000], Loss: 0.0625\n",
            "Epoch [600/10000], Loss: 0.0663\n",
            "Epoch [605/10000], Loss: 0.0678\n",
            "Epoch [610/10000], Loss: 0.0679\n",
            "Epoch [615/10000], Loss: 0.0673\n",
            "Epoch [620/10000], Loss: 0.0588\n",
            "Epoch [625/10000], Loss: 0.0616\n",
            "Epoch [630/10000], Loss: 0.0609\n",
            "Epoch [635/10000], Loss: 0.0660\n",
            "Epoch [640/10000], Loss: 0.0645\n",
            "Epoch [645/10000], Loss: 0.0728\n",
            "Epoch [650/10000], Loss: 0.0620\n",
            "Epoch [655/10000], Loss: 0.0606\n",
            "Epoch [660/10000], Loss: 0.0749\n",
            "Epoch [665/10000], Loss: 0.0618\n",
            "Epoch [670/10000], Loss: 0.0561\n",
            "Epoch [675/10000], Loss: 0.0662\n",
            "Epoch [680/10000], Loss: 0.0626\n",
            "Epoch [685/10000], Loss: 0.0673\n",
            "Epoch [690/10000], Loss: 0.0607\n",
            "Epoch [695/10000], Loss: 0.0688\n",
            "Epoch [700/10000], Loss: 0.0513\n",
            "Epoch [705/10000], Loss: 0.0612\n",
            "Epoch [710/10000], Loss: 0.0601\n",
            "Epoch [715/10000], Loss: 0.0603\n",
            "Epoch [720/10000], Loss: 0.0597\n",
            "Epoch [725/10000], Loss: 0.0549\n",
            "Epoch [730/10000], Loss: 0.0585\n",
            "Epoch [735/10000], Loss: 0.0561\n",
            "Epoch [740/10000], Loss: 0.0682\n",
            "Epoch [745/10000], Loss: 0.0588\n",
            "Epoch [750/10000], Loss: 0.0586\n",
            "Epoch [755/10000], Loss: 0.0545\n",
            "Epoch [760/10000], Loss: 0.0650\n",
            "Epoch [765/10000], Loss: 0.0703\n",
            "Epoch [770/10000], Loss: 0.0595\n",
            "Epoch [775/10000], Loss: 0.0603\n",
            "Epoch [780/10000], Loss: 0.0685\n",
            "Epoch [785/10000], Loss: 0.0622\n",
            "Epoch [790/10000], Loss: 0.0605\n",
            "Epoch [795/10000], Loss: 0.0572\n",
            "Early stopping! Epoch: 799, Best Loss: 0.05127469077706337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Το καλύτερο MLP μοντέλο είναι το 3, καθώς έχει από τα μικρότερα losses σε λιγότερες εποχές. Το πρώτο μοντέλο, ενώ είχε το πιο μικρό loss χρειάζεται περίπου τις διπλάσιες εποχές.\n",
        "Η αρχιτεκτονική του δικτύου αποτελείται από δύο κρυφά επίπεδα και ένα επιπλέον κρυφό επίπεδο που έχει προστεθεί ως επέκταση. Το μοντέλο ξεκινά με μια είσοδο διάστασης 151, που αντιπροσωπεύει τα χαρακτηριστικά μετά την εφαρμογή SVD ή κωδικοποίησης. Η πρώτη κρυφό layer έχει 100 νευρώνες, ενώ το δεύτερο και το πρόσθετο κρυφό layer έχουν από 50 νευρώνες. Το δίκτυο βγάζει έξοδο για δύο κλάσεις.\n",
        "\n",
        "Στο forward pass, το μοντέλο εφαρμόζει τη συνάρτηση ενεργοποίησης ReLU και το dropout με πιθανότητα 0.5, που βοηθά στην αποφυγή του overfitting επιβάλλοντας μια μορφή τυχαιότητας κατά την εκπαίδευση. Το μοντέλο εκπαιδεύεται με βάση τη συνάρτηση απώλειας CrossEntropyLoss, και χρησιμοποιεί τον αλγόριθμο βελτιστοποίησης Adam με ρυθμό μάθησης 0.001. Η διαδικασία εκπαίδευσης περιλαμβάνει ένα σύστημα early stopping, το οποίο διακόπτει την εκπαίδευση εάν δεν παρατηρηθεί βελτίωση στην απώλεια για έναν ορισμένο αριθμό εποχών (epochs), που ορίζεται εδώ ως patience. Αυτό είναι ένα σημαντικό χαρακτηριστικό που βοηθά στην αποφυγή χρόνου και πόρων σε μη παραγωγικές εκπαιδευτικές περιόδους και συμβάλλει στην αποτροπή του overfitting."
      ],
      "metadata": {
        "id": "ot4dyLZ9QdxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**γ)**\n",
        "\n",
        "Εφαρμόζουμε k-fold cross validation, η οποία βοηθά στη μείωση της προκατάληψης στις εκτιμήσεις απόδοσης, ενώ εξασφαλίζει ότι το μοντέλο δεν υπερπροσαρμόζεται σε συγκεκριμένο σύνολο δεδομένων, αυξάνοντας έτσι την ικανότητά του να γενικεύει σε νέα δεδομένα."
      ],
      "metadata": {
        "id": "vtDIBNr1Vi5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ορισμός του αριθμού των folds\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits)\n",
        "\n",
        "\n",
        "# Αρχικοποίηση της λίστας για την αποθήκευση των scores της ακρίβειας\n",
        "accuracy_scores = []\n",
        "# Αρχικοποίηση λιστών για τις τιμές FPR, TPR και AUC\n",
        "fprs, tprs, aucs = [], [], []\n",
        "\n",
        "for train_index, test_index in kf.split(encoded_data_tensor):\n",
        "    # Δημιουργία train και validation sets\n",
        "    X_train, X_val = encoded_data_tensor[train_index], encoded_data_tensor[test_index]\n",
        "    y_train, y_val = labels[train_index], labels[test_index]\n",
        "\n",
        "    # Εκπαίδευση του μοντέλου για κάθε fold\n",
        "    for epoch in range(num_epochs):\n",
        "        model_3.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_3(X_train.to(device))\n",
        "        loss = criterion(outputs, y_train.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Έλεγχος για early stopping\n",
        "        current_loss = loss.item()\n",
        "        if best_loss - current_loss > threshold_for_early_stop:\n",
        "            best_loss = current_loss\n",
        "            trigger_times = 0\n",
        "        else:\n",
        "            trigger_times += 1\n",
        "            if trigger_times >= patience:\n",
        "                break  # Early stopping\n",
        "\n",
        "# Αξιολόγηση του μοντέλου στο validation set\n",
        "    model_3.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model_3(X_val.to(device))\n",
        "        val_probabilities = torch.sigmoid(val_outputs)[:, 1]\n",
        "        fpr, tpr, _ = roc_curve(y_val.cpu().numpy(), val_probabilities.cpu().numpy())\n",
        "        auc_score = roc_auc_score(y_val.cpu().numpy(), val_probabilities.cpu().numpy())\n",
        "        _, predicted_labels = torch.max(val_outputs, 1)\n",
        "        acc = accuracy_score(y_val.cpu().numpy(), predicted_labels.cpu().numpy())\n",
        "\n",
        "        # Προσθήκη των αποτελεσμάτων στις λίστες\n",
        "        accuracy_scores.append(acc)\n",
        "        fprs.append(fpr)\n",
        "        tprs.append(tpr)\n",
        "        aucs.append(auc_score)\n",
        "\n",
        "# Δημιουργία των διαγραμμάτων ROC για κάθε fold\n",
        "for i in range(n_splits):\n",
        "    plt.plot(fprs[i], tprs[i], label=f'Fold {i+1} (AUC = {aucs[i]:.2f})')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for each fold')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Υπολογισμός μέσης ακρίβειας\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "print(f\"Mean accuracy over {n_splits}-folds: {mean_accuracy}\")"
      ],
      "metadata": {
        "id": "xq1hHgpVVkvw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "6ae299d0-69c9-4b75-dd7d-ba232fb42de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy over 5-folds: 0.980590717299578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Από τα παραπάνω παρατηρούμε ότι η μέση ακρίβεια είναι 0.98 και πως οι τιμές auc είναι πολύ υψηλές, δείχνοντας έτσι τη καλή απόδοση του μοντέλου."
      ],
      "metadata": {
        "id": "0gWF0eabjSLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Φόρτωση του αρχείου CSV που περιέχει τα test features\n",
        "test_features_path = '/content/final_2/Test_Features.csv'\n",
        "test_data = pd.read_csv(test_features_path, header=None)\n",
        "\n",
        "\n",
        "# Μετατροπή των δεδομένων σε numpy arrays και προεπεξεργασία με StandardScaler\n",
        "test_data_np = test_data.values.astype(np.float32)\n",
        "scaler = StandardScaler()\n",
        "test_data_np = scaler.fit_transform(test_data_np)\n",
        "\n",
        "# Μετατροπή των δεδομένων σε tensors του PyTorch\n",
        "test_data_tensor = torch.tensor(test_data_np, dtype=torch.float32).to(device)\n",
        "\n",
        "# Αξιολόγηση του autoencoder στο test set για την εξαγωγή χαρακτηριστικών χαμηλότερης διάστασης\n",
        "model_auto.eval()\n",
        "with torch.no_grad():\n",
        "    encoded_test_data = model_auto.encode(test_data_tensor)\n",
        "\n",
        "# Προβλέψεις με το μοντέλο ταξινόμησης\n",
        "model_3.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model_3(encoded_test_data)\n",
        "    test_probabilities = torch.sigmoid(test_outputs)[:, 1]\n",
        "    # print(test_probabilities)\n",
        "    _, predicted_labels = torch.max(test_outputs, 1)\n",
        "\n",
        "# Καταγραφή των προβλέψεων και σκορ σε DataFrame\n",
        "predicted_labels_np = predicted_labels.cpu().numpy()\n",
        "test_probabilities_np = test_probabilities.cpu().numpy()\n",
        "predictions_df = pd.DataFrame({\n",
        "    'predicted_label': predicted_labels_np,\n",
        "    'prediction_score': test_probabilities_np\n",
        "})\n",
        "\n",
        "# Αποθήκευση σε CSV\n",
        "output_csv_path = '/content/final_2/test_predictions.csv'\n",
        "predictions_df.to_csv(output_csv_path, index=False)\n"
      ],
      "metadata": {
        "id": "SLbG04Z8jpUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Στη γραμμή test_probabilities = torch.sigmoid(test_outputs)[:, 1], χρησιμοποιούμε τη σιγμοειδή συνάρτηση για να μετατρέψει τις πρώτες εξόδους, πριν εφαρμοστεί η συνάρτηση ενεργοποίησης, σε πιθανότητες. Επιλέγοντας τη δεύτερη στήλη ([:, 1]), λαμβάνουμε την πιθανότητα το δείγμα να ανήκει στην κλάση 1. Έτσι, το \"prediction score\"  είναι ουσιαστικά αυτή η πιθανότητα. Αν η τιμή είναι κοντά στο 1, το μοντέλο είναι πολύ σίγουρο ότι το δείγμα ανήκει στην κλάση 1. Αντίστοιχα, μια τιμή κοντά στο 0 σημαίνει ότι το μοντέλο είναι πολύ σίγουρο ότι το δείγμα δεν ανήκει στην κλάση 1."
      ],
      "metadata": {
        "id": "mO5aWsgED6Pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Γενικό Σχόλιο**\n",
        "\n",
        "Γενικά, τα αποτελέσματα μπορεί να διαφέρουν σε κάθε run, δεν μπόρεσα να το αλλάξω. Για αυτό, πχ σε αυτό το run φαίνεται ότι το MLP_3 έχει λίγο παραπάνω loss."
      ],
      "metadata": {
        "id": "2ISe5eX3jU1q"
      }
    }
  ]
}
